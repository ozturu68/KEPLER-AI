import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import io
import shap
import matplotlib.pyplot as plt
import warnings
import time 
import logging
from typing import Tuple, Dict, Any, List

# KRÄ°TÄ°K Ä°MPORT: Streamlit'in dahili yeniden Ã§alÄ±ÅŸtÄ±rma istisnasÄ±nÄ± yakalamak iÃ§in.
#from streamlit.runtime.scriptrunner.exceptions import RerunException 


# --- UYGULAMA YAPILANDIRMASI ve SABÄ°TLER ---

# Matplotlib backend ayarÄ± ve uyarÄ±larÄ± bastÄ±rma
try:
    plt.switch_backend('Agg')
except ImportError:
    pass

warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
pd.options.mode.chained_assignment = None

REQUIRED_COLUMNS = ['koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 
                    'koi_fpflag_co', 'koi_period', 'koi_depth', 
                    'koi_prad', 'koi_steff']

# Ä°yileÅŸtirme: Merkezi durum seÃ§enekleri
INVESTIGATION_STATUS_OPTIONS = ["Yeni Aday", "Ä°ncelemeye AlÄ±ndÄ±", "YanlÄ±ÅŸ Pozitif (FP)", "OnaylandÄ± (NP)"]

# Loglama AyarlarÄ±
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(funcName)s - %(message)s') 
logger = logging.getLogger(__name__)

# Streamlit Sayfa AyarlarÄ±
st.set_page_config(
    page_title="Kepler-AI | Ã–tegezegen SÄ±nÄ±flandÄ±rma",
    layout="wide",
    initial_sidebar_state="auto"
)

# --- TASARIM Ä°Ã‡Ä°N GÃœNCEL CSS ---
st.markdown("""
<style>
    /* Ana iÃ§erik alanÄ±nÄ± sÄ±nÄ±rla ve ortala */
    .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        padding-left: 5rem;
        padding-right: 5rem;
        max-width: 1400px;
    }
    
    /* Vurgu Rengi (Kepler Mavisi/Cyan) */
    :root {
        --primary-color: #7FE9F0; 
    }

    /* Streamlit'in varsayÄ±lan birincil rengini (butonu vb.) deÄŸiÅŸtirme */
    .st-emotion-cache-16fvj8 {
        background-color: #7FE9F0 !important;
        color: #0E1117 !important;
    }
    
    /* BaÅŸlÄ±k Stilini GeliÅŸtirme */
    h1 {
        font-size: 2.5em;
        font-weight: 300; 
        color: #FF4B4B; 
        text-align: center;
        border-bottom: 2px solid #262730; 
        padding-bottom: 10px;
    }
    
    /* Sidebar baÅŸlÄ±klarÄ±nÄ± alet kutusu gibi daha belirgin yap */
    #sidebar .st-emotion-cache-1ftru4k, #sidebar .st-emotion-cache-10ohe8r {
        border-bottom: 1px solid #7FE9F0; 
        padding-bottom: 5px;
        margin-top: 20px;
    }
    
</style>
""", unsafe_allow_html=True)


# -----------------------------------------------------------
# 1. ML VARLIKLARINI CACHING EDEN FONKSÄ°YON 
# -----------------------------------------------------------

@st.cache_resource(show_spinner="ğŸ‘½ Yapay Zeka VarlÄ±klarÄ± YÃ¼kleniyor...")
def load_ml_assets_cached():
    """Modeli, Ã¶lÃ§ekleyiciyi ve SHAP Explainer'Ä± gÃ¼venle yÃ¼kler."""
    MODEL_PATH = 'models/kepler_ai_best_model.joblib'
    SCALER_PATH = 'models/kepler_ai_scaler.joblib'
    FEATURES_PATH = 'models/kepler_ai_feature_names.joblib'
    
    try:
        if not os.path.exists(MODEL_PATH) or not os.path.exists(SCALER_PATH):
            logger.error(f"Model dosyalarÄ± bulunamadÄ±: {MODEL_PATH} veya {SCALER_PATH}")
            raise FileNotFoundError("Model dosyalarÄ± bulunamadÄ±.")

        model = joblib.load(MODEL_PATH)
        scaler = joblib.load(SCALER_PATH)
        feature_names_list = joblib.load(FEATURES_PATH)
        explainer = shap.TreeExplainer(model) 
        logger.info("ML varlÄ±klarÄ± baÅŸarÄ±yla yÃ¼klendi.")
        
        return model, scaler, feature_names_list, explainer
    except Exception as e:
        logger.exception("Model yÃ¼kleme sÄ±rasÄ±nda beklenmeyen bir hata oluÅŸtu.")
        st.error(f"Model yÃ¼kleme sÄ±rasÄ±nda beklenmeyen bir hata oluÅŸtu: {e}")
        return None, None, None, None

# -----------------------------------------------------------
# 2. MODEL SÄ°STEMÄ° SINIFI (Tahmin ve Yorumlama Boru HattÄ±)
# -----------------------------------------------------------

class ExoplanetClassifier:
    """Makine Ã¶ÄŸrenimi boru hattÄ±nÄ± yÃ¶neten ana sÄ±nÄ±f."""
    
    def __init__(self):
        self.model, self.scaler, self.feature_names, self.explainer = load_ml_assets_cached()
        if self.model is None or self.scaler is None:
             logger.critical("Model veya Ã¶lÃ§ekleyici yÃ¼klenemedi. Uygulama baÅŸlatÄ±lamÄ±yor.")
             raise RuntimeError("Model yÃ¼klenemedi. Devam edilemiyor.")
        logger.info("ExoplanetClassifier instance baÅŸarÄ±yla oluÅŸturuldu.")

    @staticmethod
    @st.cache_data(show_spinner="âš™ï¸ Veri Temizleme ve Validasyon Ä°ÅŸleniyor...")
    def _validate_and_clean_data(df_raw: pd.DataFrame, required_columns: list) -> Tuple[pd.DataFrame, List[str]]:
        df = df_raw.copy()
        initial_count = len(df)
        issues = []
        
        # Temel sÃ¼tunlarÄ± sayÄ±sal tiplere zorla
        for col in ['koi_score', 'koi_period', 'koi_depth', 'koi_prad', 'koi_steff']:
            if col in df.columns:
                 df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # GeÃ§ersiz (Inf, NaN) deÄŸerleri temizle
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        df_cleaned = df.dropna(subset=required_columns)
        dropped_nan_count = initial_count - len(df_cleaned)
        if dropped_nan_count > 0:
            issues.append(f"{dropped_nan_count} satÄ±rda temel Ã¶zelliklerde eksik/geÃ§ersiz (NaN/Inf/SayÄ±sal Olmayan) deÄŸer olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±.")
        
        df = df_cleaned.copy()
        
        # SÄ±fÄ±r veya negatif deÄŸerleri kontrol et
        for col, label in [('koi_period', 'yÃ¶rÃ¼nge periyodu'), ('koi_prad', 'gezegen yarÄ±Ã§apÄ±'), ('koi_depth', 'geÃ§iÅŸ derinliÄŸi')]:
            dropped_count = len(df[df[col] <= 0])
            df = df[df[col] > 0]
            if dropped_count > 0:
                 issues.append(f"{dropped_count} satÄ±rda {label} sÄ±fÄ±r veya negatif olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±.")

        # Skor aralÄ±ÄŸÄ± [0, 1] kontrolÃ¼
        dropped_score_count = len(df[(df['koi_score'] < 0) | (df['koi_score'] > 1)])
        df = df[(df['koi_score'] >= 0) & (df['koi_score'] <= 1)]
        if dropped_score_count > 0:
            issues.append(f"{dropped_score_count} satÄ±rda skor [0, 1] aralÄ±ÄŸÄ± dÄ±ÅŸÄ±nda olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±.")
            
        # FP bayraklarÄ± kontrolÃ¼ (0 veya 1 olmalÄ±)
        fp_cols = ['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co']
        for col in fp_cols:
            if col in df.columns:
                 df[col] = pd.to_numeric(df[col], errors='coerce').fillna(-1).astype(int) 
                 invalid_flag_count = len(df[(df[col] != 0) & (df[col] != 1)])
                 df = df[(df[col] == 0) | (df[col] == 1)]
                 if invalid_flag_count > 0:
                      issues.append(f"{invalid_flag_count} satÄ±rda '{col}' bayraÄŸÄ± 0 veya 1 dÄ±ÅŸÄ±nda/geÃ§ersiz olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±.")

        final_count = len(df)
        if final_count < initial_count:
            issues.insert(0, f"**Toplam {initial_count - final_count} satÄ±r KONTROL SÄ°STEMÄ° tarafÄ±ndan geÃ§ersiz veri nedeniyle atÄ±ldÄ±.**")
        
        logger.info(f"Veri temizleme tamamlandÄ±. BaÅŸlangÄ±Ã§: {initial_count}, Son: {final_count}")
        return df, issues
    
    @staticmethod
    def _feature_engineering_and_alignment(df_raw_row: pd.DataFrame, feature_names: list) -> pd.DataFrame:
        df_new = df_raw_row.copy()
        EPSILON = 1e-12 

        # Log dÃ¶nÃ¼ÅŸÃ¼mleri
        df_new['R_PRAD_log'] = np.log10(df_new['koi_prad'].replace(0, EPSILON))
        df_new['R_PERIOD_log'] = np.log10(df_new['koi_period'].replace(0, EPSILON))
        df_new['R_DEPTH_log'] = np.log10(df_new['koi_depth'].replace(0, EPSILON))
        
        # Yeni tÃ¼retilmiÅŸ Ã¶zellikler
        df_new['koi_density_proxy'] = df_new['koi_prad'] / (df_new['koi_period'].replace(0, EPSILON) ** (1/3))
        df_new['koi_depth_teff_int'] = df_new['koi_depth'] * df_new['koi_steff']
        
        # Ã–zellik hizalama (Modelin beklediÄŸi tÃ¼m sÃ¼tunlarÄ± oluÅŸtur)
        df_aligned = pd.DataFrame(0.0, index=df_new.index, columns=feature_names, dtype=np.float64)
        
        for col in df_new.columns:
            if col in df_aligned.columns:
                df_aligned.loc[:, col] = df_new.loc[:, col].astype(np.float64)
                
        return df_aligned
    
    def _get_confidence_robust(self, X_scaled: np.ndarray, num_runs: int = 10) -> Tuple[str, float]:
        """Model tahminini birden Ã§ok kez jitter'lÄ± veri ile yaparak kararlÄ±lÄ±ÄŸÄ± artÄ±rÄ±r."""
        JITTER_SCALE = 0.001 
        all_probabilities = []
        
        for _ in range(num_runs):
            X_jittered = X_scaled + np.random.normal(0, JITTER_SCALE, X_scaled.shape)
            proba = self.model.predict_proba(X_jittered)[0]
            all_probabilities.append(proba)
            
        avg_probabilities = np.mean(all_probabilities, axis=0)
        
        prediction_label = "GEZEGEN/ADAY" if avg_probabilities[1] > 0.5 else "YANLIÅ POZÄ°TÄ°F (FALSE POSITIVE)"
        confidence = max(avg_probabilities)
        
        return prediction_label, confidence
    
    def predict(self, df_raw: pd.DataFrame, row_index: int) -> Tuple[str, float, io.BytesIO, Dict[str, Any]]:
        df_raw_row = df_raw.iloc[[row_index]]
        logger.info(f"Aday {row_index+1} iÃ§in tahmin baÅŸlatÄ±ldÄ±.")
            
        try:
            X_aligned = self._feature_engineering_and_alignment(df_raw_row, self.feature_names)
            X_scaled = self.scaler.transform(X_aligned.values)
            prediction_label, confidence = self._get_confidence_robust(X_scaled, num_runs=10)
            
            # SHAP DeÄŸerlerini Hesapla
            shap_values = self.explainer.shap_values(X_scaled) 
            
            if isinstance(shap_values, list):
                # SÄ±nÄ±f 1 (Pozitif/Gezegen) iÃ§in deÄŸerleri kullan
                target_class_index = 1 if len(shap_values) > 1 else 0
                values_to_plot = shap_values[target_class_index][0] 
                base_value_to_plot = self.explainer.expected_value[target_class_index]
            else:
                values_to_plot = shap_values[0]
                base_value_to_plot = self.explainer.expected_value

            if isinstance(base_value_to_plot, np.ndarray) and base_value_to_plot.ndim > 0:
                 base_value_to_plot = base_value_to_plot.flatten()[0]
            
            shap_plot_data = shap.Explanation(
                values=values_to_plot, 
                base_values=base_value_to_plot, 
                data=X_scaled[0], 
                feature_names=self.feature_names
            )
            
            # SHAP GÃ¶rselini OluÅŸtur ve Bellekte Sakla
            plt.style.use('dark_background') 
            fig = plt.figure(figsize=(18, 12)) 
            shap.plots.waterfall(shap_plot_data, max_display=15, show=False)
            plt.tight_layout()

            buf = io.BytesIO()
            fig.savefig(buf, format='png', dpi=200, bbox_inches='tight', facecolor='#0E1117') 
            buf.seek(0)
            plt.close(fig) 

            logger.info(f"Aday {row_index+1} iÃ§in tahmin tamamlandÄ±: {prediction_label}, GÃ¼ven: {confidence:.2%}")
            
            return prediction_label, confidence, buf, df_raw_row.iloc[0].to_dict()

        except Exception as e:
            logger.exception(f"Aday {row_index+1} iÃ§in tahmin/SHAP Ã¼retimi sÄ±rasÄ±nda kritik hata oluÅŸtu.")
            raise RuntimeError(f"Tahmin ve SHAP Ã¼retimi sÄ±rasÄ±nda kritik hata: {e}")


# -----------------------------------------------------------
# 3. STREAMLIT ANA UYGULAMA MANTIÄI
# -----------------------------------------------------------

try:
    CLASSIFIER = ExoplanetClassifier()
except RuntimeError as e:
    logger.critical(f"Uygulama baÅŸlatÄ±lamadÄ±: {e}")
    st.error(f"Uygulama Ã‡alÄ±ÅŸtÄ±rma HatasÄ±: {e}. Model varlÄ±klarÄ±nÄ±n doÄŸru yÃ¼klendiÄŸinden emin olun.")
    st.stop()


# --- MERKEZÄ° ODAKLI BAÅLIK ALANI ---
with st.container():
    col_left_title, col_center_title, col_right_title = st.columns([1, 3, 1])

    with col_center_title:
        st.title("ğŸ”­ Kepler-AI: Ã–tegezegen KeÅŸif AsistanÄ±")
        st.markdown("### <p style='text-align: center; color: #7FE9F0;'>Model Yorumlanabilirlik (XAI) ile desteklenen yÃ¼ksek gÃ¼venilirlikli analiz platformu.</p>", unsafe_allow_html=True)
    st.markdown("---")


def run_simulation_animation(candidate_name, total_duration=3.0):
    """ANALÄ°Z SÃœRESÄ° OPTÄ°MÄ°ZASYONU: 3.0 saniyelik gÃ¶rsel bekleme barÄ±."""
    col_left_anim, col_center_anim, col_right_anim = st.columns([1, 3, 1])
    
    with col_center_anim:
        status_placeholder = st.empty()
        progress_bar = st.progress(0)
        
        status_placeholder.subheader(f"ğŸ’« Aday {candidate_name} iÃ§in YÃ¼ksek GÃ¼venilirlikli Analiz BaÅŸlatÄ±ldÄ±...")
        
        stages = [(0.1, "1/3: Veri Ã–zellikleri HizalanÄ±yor..."), (0.4, "2/3: Monte Carlo SimÃ¼lasyonu BaÅŸlatÄ±ldÄ±..."), (0.8, "3/3: Yapay Zeka Modeli Son OlasÄ±lÄ±k SkorlarÄ±nÄ± BirleÅŸtiriyor."), (1.0, "âœ… Analiz TamamlandÄ±! Karar AÃ§Ä±klamasÄ± OluÅŸturuldu.")]
        current_progress = 0.0
        start_time = time.time()
        
        for target_progress, message in stages:
            progress_bar.progress(int(target_progress * 100))
            status_placeholder.markdown(f"**{message}**")
            time_to_wait = total_duration * (target_progress - current_progress) * 0.9 
            time.sleep(time_to_wait)
            current_progress = target_progress

        remaining_time = total_duration - (time.time() - start_time)
        if remaining_time > 0:
            time.sleep(remaining_time)
        
        progress_bar.empty()
        status_placeholder.empty()
        st.success(f"âœ… Analiz BaÅŸarÄ±lÄ±.")
        time.sleep(0.5)


# Ä°yileÅŸtirme: FP BayraklarÄ±nÄ± daha anlaÅŸÄ±lÄ±r metne dÃ¶nÃ¼ÅŸtÃ¼ren yardÄ±mcÄ± fonksiyon
def map_flag_to_text(flag_val, name):
    """0/1 flag deÄŸerini aÃ§Ä±klayÄ±cÄ± metin ve emojiye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    if flag_val == 1:
         return f"âŒ Bayrak KaldÄ±rÄ±ldÄ± ({name})"
    return f"âœ… Normal (Temiz)"


def main_prediction_page():
    """TEKÄ°L ADAY ANALÄ°ZÄ° SAYFASI (Ana GÃ¶rÃ¼nÃ¼m)"""
    
    if st.session_state.df_raw is None:
        st.error("LÃ¼tfen Ã¶nce veri yÃ¼kleme sayfasÄ±ndan geÃ§erli bir Kepler veri seti yÃ¼kleyin.")
        return

    # Ä°YÄ°LEÅTÄ°RME 1: Veri Seti Genel Durumu Ã–zeti
    st.subheader("ğŸ“Š YÃ¼klenen Veri Seti Genel Durumu")
    
    df_raw = st.session_state.df_raw
    
    # EtiketlenmiÅŸ aday sayÄ±sÄ±nÄ± hesapla
    labeled_count = len(df_raw[df_raw['Investigation_Status'] != "Yeni Aday"])
    
    # Ortalama periyodu gÃ¼venli bir ÅŸekilde hesapla
    mean_period = df_raw['koi_period'].mean() if not df_raw.empty else 0.0
    
    col1, col2, col3 = st.columns(3)
    with col1:
         st.metric("Toplam Analiz Edilebilir Aday", len(df_raw))
    with col2:
         st.metric("EtiketlenmiÅŸ Aday SayÄ±sÄ±", labeled_count)
    with col3:
         st.metric("Ortalama YÃ¶rÃ¼nge Periyodu", f"{mean_period:.2f} GÃ¼n")
    st.markdown("---")


    # --- Analiz SonuÃ§larÄ±nÄ±n GÃ¶sterilmesi ---
    if 'show_results' in st.session_state and st.session_state.show_results:
        prediction, confidence, shap_buffer, raw_data = st.session_state.last_prediction
        
        st.header(f"2. ğŸ›°ï¸ Aday {st.session_state.selected_candidate_index+1} iÃ§in Analiz Raporu")
        st.markdown("---")
        
        is_false_positive = "YANLIÅ" in prediction
        emoji = "ğŸš¨" if is_false_positive else "âœ…"
        color = "#7FE9F0" if not is_false_positive else "#DC3545" 
        
        # --- SONUÃ‡ VE GÃœVEN METRÄ°KLERÄ° ---
        st.subheader("ğŸ¯ Tahmin ve GÃ¼ven Ã–zeti")
        
        col_pred, col_conf, col_empty = st.columns([3, 2, 1]) 
        
        with col_pred:
            st.markdown(f"""
            <div style='background-color: #262730; padding: 15px; border-radius: 10px; border-left: 8px solid {color}; box-shadow: 0 4px 12px 0 rgba(0,0,0,0.3);'>
                <p style='font-size: 1.1em; margin: 0; color: #AFAFAF; font-weight: 500;'>SÄ±nÄ±flandÄ±rma Sonucu</p>
                <h1 style='color: {color}; margin: 5px 0 0 0;'>{emoji} {prediction}</h1>
            </div>
            """, unsafe_allow_html=True)
        
        with col_conf:
            st.metric(label="Model GÃ¼ven Skoru", value=f"{confidence:.2%}") 
        
        st.markdown("<br>", unsafe_allow_html=True)

        # --- ASTROFÄ°ZÄ°KSEL VERÄ°LER VE BAYRAKLAR ---
        st.subheader("ğŸ”­ Temel Parametreler")
        col_prad, col_period, col_depth, col_steff, col_score = st.columns(5)
        
        with col_prad: st.metric(r"Gezegen YarÄ±Ã§apÄ± ($R_{\oplus}$)", f"{raw_data.get('koi_prad', 0.0):.2f}")
        with col_period: st.metric("YÃ¶rÃ¼nge Periyodu", f"{raw_data.get('koi_period', 0.0):.2f} GÃ¼n")
        with col_depth: st.metric("GeÃ§iÅŸ DerinliÄŸi", f"{raw_data.get('koi_depth', 0.0):.2e} ppm")
        with col_steff: st.metric("YÄ±ldÄ±z SÄ±caklÄ±ÄŸÄ±", f"{raw_data.get('koi_steff', 0.0):.0f} K")
        with col_score: st.metric("Kepler/KOI Skoru", f"{raw_data.get('koi_score', 0.0):.3f}")

        st.markdown("---")

        # --- SHAP GÃ–RSELÄ° ---
        st.header("ğŸ”¬ Modelin Karar Analizi (XAI)")
        st.info("SHAP Waterfall Plot, modelin tahminini hangi Ã¶zelliklerin, hangi yÃ¶nde (pozitif/negatif) ve ne kadar etkilediÄŸini gÃ¶sterir.")
        
        st.image(shap_buffer, caption=f'Aday {st.session_state.selected_candidate_index+1} iÃ§in SHAP Etki GÃ¶rseli')
    
    else:
         st.info("LÃ¼tfen sol taraftaki Aday SeÃ§imi bÃ¶lÃ¼mÃ¼nden bir aday seÃ§in ve 'Analiz Et' butonuna tÄ±klayÄ±n.")


def collective_analysis_page():
    """TOPLU VERÄ° SETÄ° Ä°NCELEMESÄ° SAYFASI (Ana GÃ¶rÃ¼nÃ¼m)"""
    
    if st.session_state.df_raw is None:
        st.error("LÃ¼tfen Ã¶nce veri yÃ¼kleme sayfasÄ±ndan geÃ§erli bir Kepler veri seti yÃ¼kleyin.")
        return
        
    df_raw = st.session_state.df_raw
    
    # --- Sidebar'dan Filtreleri Uygula ---
    period_range = st.session_state.period_range
    score_threshold = st.session_state.score_threshold
    status_filter = st.session_state.status_filter 
         
    # TÃ¼m filtreleri uygula
    df_filtered = df_raw[
        (df_raw['koi_period'] >= period_range[0]) & 
        (df_raw['koi_period'] <= period_range[1]) &
        (df_raw['koi_score'] >= score_threshold) &
        (df_raw['Investigation_Status'].isin(status_filter))
    ]
    
    # Ä°yileÅŸtirme: GÃ¶rsel Netlik iÃ§in FP bayraklarÄ±nÄ± Ã§evir
    df_display = df_filtered.copy()
    df_display['FP_NT'] = df_display['koi_fpflag_nt'].apply(lambda x: map_flag_to_text(x, "GÃ¼rÃ¼ltÃ¼"))
    df_display['FP_SS'] = df_display['koi_fpflag_ss'].apply(lambda x: map_flag_to_text(x, "Ã‡oklu Sistem"))
    df_display['FP_CO'] = df_display['koi_fpflag_co'].apply(lambda x: map_flag_to_text(x, "Merkez KaymasÄ±"))
         
    # --- UI ---
    st.header("ğŸ“‹ Toplu Veri Seti Ä°ncelemesi")
    st.info("Sol taraftaki (Alet Ã‡antasÄ±) filtreleri kullanarak bu tabloyu anlÄ±k olarak daraltabilirsiniz. **'Ä°nceleme Durumu'** sÃ¼tununu doÄŸrudan tabloda dÃ¼zenleyebilirsiniz.")
    
    st.markdown(f"**Toplam Analiz Edilebilir Aday:** **<span style='color:#7FE9F0;'>{len(df_raw)}</span>**", unsafe_allow_html=True)
    st.markdown(f"**FiltrelenmiÅŸ SonuÃ§ SayÄ±sÄ±:** **<span style='color:#FF9900;'>{len(df_filtered)}</span>**", unsafe_allow_html=True)
    st.markdown("---")

    st.subheader("ğŸ” Aday Ä°nceleme Tablosu")
    
    # Ä°YÄ°LEÅTÄ°RME 2: Durum Renk KodlarÄ± AÃ§Ä±klamasÄ±
    status_colors = {
        "Yeni Aday": "#5A5E66",           
        "Ä°ncelemeye AlÄ±ndÄ±": "#FF9900",   
        "YanlÄ±ÅŸ Pozitif (FP)": "#DC3545", 
        "OnaylandÄ± (NP)": "#7FE9F0"       
    }
    st.markdown(f"""
    <div style='display: flex; gap: 20px; margin-bottom: 20px;'>
        <span style='color: {status_colors["Yeni Aday"]}; font-weight: bold;'>âš« Yeni Aday</span>
        <span style='color: {status_colors["Ä°ncelemeye AlÄ±ndÄ±"]}; font-weight: bold;'>ğŸŸ  Ä°ncelemeye AlÄ±ndÄ±</span>
        <span style='color: {status_colors["YanlÄ±ÅŸ Pozitif (FP)"]}; font-weight: bold;'>ğŸ”´ FP</span>
        <span style='color: {status_colors["OnaylandÄ± (NP)"]}; font-weight: bold;'>ğŸ”µ OnaylandÄ±</span>
    </div>
    """, unsafe_allow_html=True)
    
    # GÃ¶rÃ¼ntÃ¼lenecek sÃ¼tunlarÄ± belirle: Orijinal FP'ler yerine yeni, aÃ§Ä±klayÄ±cÄ± sÃ¼tunlarÄ± kullan.
    columns_to_show = [
        'koi_score', 'koi_period', 'koi_prad', 'koi_depth', 
        'FP_NT', 'FP_SS', 'FP_CO', 'Investigation_Status' 
    ]
    df_display = df_display.filter(items=columns_to_show)

    # ğŸ’¥ st.data_editor ile interaktif etiketleme ve gÃ¶rsel netlik
    edited_df_view = st.data_editor(
        df_display, 
        use_container_width=True, 
        hide_index=False,
        column_config={
            "koi_score": st.column_config.ProgressColumn("Kepler Skoru", format="%.3f", min_value=0, max_value=1),
            "koi_prad": st.column_config.NumberColumn(label=r"Gezegen YarÄ±Ã§apÄ± ($R_{\oplus}$)", format="%.2f"),
            "koi_period": st.column_config.NumberColumn(label="YÃ¶rÃ¼nge Periyodu (GÃ¼n)", format="%.2f"),
            "koi_depth": st.column_config.NumberColumn(label="GeÃ§iÅŸ DerinliÄŸi (ppm)", format="%.1f"),
            # Yeni FP KolonlarÄ± iÃ§in config - DÃ¼zenlenemez yapÄ±ldÄ±
            "FP_NT": st.column_config.TextColumn("GÃ¼rÃ¼ltÃ¼ BayraÄŸÄ± (NT)", help="GÃ¼rÃ¼ltÃ¼ye baÄŸlÄ± yanlÄ±ÅŸ pozitif bayraÄŸÄ±", disabled=True),
            "FP_SS": st.column_config.TextColumn("Ã‡oklu Sistem (SS)", help="Ã‡oklu sistem bayraÄŸÄ±", disabled=True),
            "FP_CO": st.column_config.TextColumn("Merkez KaymasÄ± (CO)", help="Merkez kaymasÄ± bayraÄŸÄ±", disabled=True),
            "Investigation_Status": st.column_config.SelectboxColumn( # DÃ¼zenlenebilir Etiketleme
                "Ä°nceleme Durumu (Etiketle)",
                options=INVESTIGATION_STATUS_OPTIONS,
                required=True,
                default="Yeni Aday",
                width="medium"
            )
        },
    )
    
    # ğŸŒŸ ETÄ°KETLEME DEÄÄ°ÅÄ°KLÄ°KLERÄ°NÄ° KALICI HALE GETÄ°RME (Ana DF'ye yazma)
    original_status_series = df_raw.loc[df_filtered.index, 'Investigation_Status']
    edited_status_series = edited_df_view['Investigation_Status']
    
    # YalnÄ±zca status sÃ¼tununda bir deÄŸiÅŸiklik varsa devam et
    if not edited_status_series.equals(original_status_series):
        
        # DeÄŸiÅŸen deÄŸerlerin indekslerini bul
        changed_indices = edited_status_series[edited_status_series != original_status_series].index
        
        # Ana DataFrame (st.session_state.df_raw) Ã¼zerindeki ilgili satÄ±rlarÄ± gÃ¼ncelle
        for index in changed_indices:
             new_status = edited_df_view.loc[index, 'Investigation_Status']
             st.session_state.df_raw.loc[index, 'Investigation_Status'] = new_status
        
        # DeÄŸiÅŸikliklerin Streamlit'te kalÄ±cÄ± olmasÄ± ve filtrelemeye yansÄ±masÄ± iÃ§in yeniden Ã§alÄ±ÅŸtÄ±r
        st.rerun() 
        
    # Ä°yileÅŸtirme: Veriyi Ä°ndirme Butonu Ekleme
    st.markdown("---")
    st.subheader("â¬‡ï¸ Veriyi DÄ±ÅŸa Aktar")
    
    @st.cache_data
    def convert_df_to_csv(df_filtered_placeholder):
        # Filtrelenen DF'in index'lerini kullanarak ana DF'ten sadece filtrelenmiÅŸ satÄ±rlarÄ± al
        # Bu, en gÃ¼ncel Investigation_Status dahil tÃ¼m verileri iÃ§erir.
        df_to_export = st.session_state.df_raw.loc[df_filtered_placeholder.index].copy()
        
        # Sadece temel KOI sÃ¼tunlarÄ±nÄ± ve Investigation_Status'Ä± dahil et
        export_cols_base = REQUIRED_COLUMNS + ['Investigation_Status']
        
        # KOI ile baÅŸlayan tÃ¼m sÃ¼tunlarÄ± da dahil et (Ã¶r: koi_disposition, koi_score_err)
        available_cols = [col for col in df_to_export.columns if col.startswith('koi_') or col in export_cols_base]
        
        df_to_export = df_to_export.filter(items=list(set(available_cols)))
        
        return df_to_export.to_csv(index=False).encode('utf-8')
    
    csv = convert_df_to_csv(df_filtered) # df_filtered, gÃ¼ncel filtreleri temsil eder
    
    st.download_button(
        label="Aktif Filtrelerle EtiketlenmiÅŸ Veriyi Ä°ndir (CSV)",
        data=csv,
        file_name='kepler_analysis_data.csv',
        mime='text/csv',
        type="secondary",
        use_container_width=True
    )
        

# -----------------------------------------------------------
# 4. UYGULAMA ANA GÃ–VDESÄ° VE DÄ°NAMÄ°K SÄ°DEBAR
# -----------------------------------------------------------

upload_placeholder = st.empty()
uploaded_file = None 

# Session State'leri baÅŸlat
if 'df_raw' not in st.session_state: st.session_state.df_raw = None
if 'page_selection' not in st.session_state: st.session_state.page_selection = "âœ¨ Tekil Aday Analizi"
if 'show_results' not in st.session_state: st.session_state.show_results = False
if 'last_prediction' not in st.session_state: st.session_state.last_prediction = None
if 'validation_issues' not in st.session_state: st.session_state.validation_issues = None
if 'run_analysis' not in st.session_state: st.session_state.run_analysis = -1
if 'selected_candidate_index' not in st.session_state: st.session_state.selected_candidate_index = 0
if 'period_range' not in st.session_state: st.session_state.period_range = (0.0, 1000.0)
if 'score_threshold' not in st.session_state: st.session_state.score_threshold = 0.0
if 'status_filter' not in st.session_state: st.session_state.status_filter = INVESTIGATION_STATUS_OPTIONS 

# --- VERÄ° YÃœKLEME KONTROLÃœ (BaÅŸlangÄ±Ã§ SayfasÄ±) ---
if st.session_state.df_raw is None:
    
    with upload_placeholder.container():
        st.markdown("<br><br><br>", unsafe_allow_html=True)
        col_left, col_center, col_right = st.columns([2, 3, 2]) 
        
        with col_center:
            st.header("1. Kepler Veri Setini YÃ¼kle ğŸŒ ")
            st.markdown("### **<span style='color:#FF9900;'>Yapay Zeka ile Ã–tegezegen AdaylarÄ±nÄ± Bir TÄ±kla Temizle ve Analiz Et.</span>**", unsafe_allow_html=True)
            st.markdown("---")
            
            with st.expander("â“ Veri Gereksinimleri ve GÃ¼venlik Ã–nlemi"):
                 st.markdown("""
                 - **Veri GizliliÄŸi:** YÃ¼klediÄŸiniz dosya, sadece bu oturum iÃ§in kullanÄ±lÄ±r ve sunucularda saklanmaz.
                 - **Gereken Format:** DosyanÄ±zÄ±n Kepler/KOI formatÄ±nda, baÅŸlÄ±k kÄ±smÄ± atlanabilir (`skiprows=14`) ve **`koi_score`, `koi_period`, `koi_prad`** gibi zorunlu sÃ¼tunlarÄ± iÃ§ermesi gerekir.
                 - **GÃ¼venlik (Code Injection) Ã–nlemi:** YÃ¼klenen CSV dosyasÄ±ndaki tÃ¼m sayÄ±sal sÃ¼tunlar Ã¶zel bir sistem tarafÄ±ndan zorla sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. EÄŸer bu sÃ¼tunlarda kÃ¶tÃ¼ niyetli metin veya komut bulunursa, bunlar zararsÄ±z `NaN` deÄŸerlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve otomatik olarak temizlenir.
                 """)

            uploaded_file = st.file_uploader(
                "LÃ¼tfen filtrelenmiÅŸ Kepler/KOI CSV dosyasÄ±nÄ± buraya sÃ¼rÃ¼kle bÄ±rak veya TÄ±kla (.csv)", 
                type=['csv'],
                key="main_uploader"
            )

# --- DOSYA Ä°ÅLEME VE YENÄ°DEN Ã‡ALIÅTIRMA (RERUN) ---
if uploaded_file is not None and st.session_state.df_raw is None:
    upload_placeholder.empty()

    try:
        df_raw = pd.read_csv(uploaded_file, skiprows=14) 
        
        missing_cols = [col for col in REQUIRED_COLUMNS if col not in df_raw.columns]
        if missing_cols:
            st.error(f"Hata: Eksik zorunlu sÃ¼tunlar var: **{', '.join(missing_cols)}**")
            st.session_state.df_raw = None
            st.stop() 

        # Veri Temizleme ve Validasyon
        df_cleaned, validation_issues = ExoplanetClassifier._validate_and_clean_data(df_raw, REQUIRED_COLUMNS)
        
        if df_cleaned.empty:
            st.error("Hata: YÃ¼klenen dosyada tÃ¼m gÃ¼venlik ve temizlik kontrollerini geÃ§en geÃ§erli aday kalmadÄ±.")
            st.session_state.df_raw = None
            st.stop()
            
        # Ä°nceleme Durumu (Investigation_Status) sÃ¼tununu ekle
        if 'Investigation_Status' not in df_cleaned.columns:
             df_cleaned['Investigation_Status'] = INVESTIGATION_STATUS_OPTIONS[0]
             
        st.session_state.df_raw = df_cleaned
        st.session_state.validation_issues = validation_issues
        st.session_state.show_results = False
        st.session_state.last_prediction = None
        st.session_state.selected_candidate_index = 0
        
# Filtre aralÄ±klarÄ±nÄ± yÃ¼klenen veriye gÃ¶re ayarla
        min_p = df_cleaned['koi_period'].min()
        max_p = df_cleaned['koi_period'].max()
        st.session_state.period_range = (min_p, max_p) if min_p < max_p else (min_p, min_p + 1) # Tek deÄŸerse slider'Ä± bozmamak iÃ§in +1
        st.session_state.score_threshold = 0.0
        st.session_state.status_filter = INVESTIGATION_STATUS_OPTIONS # Yeni filtreyi varsayÄ±lana ayarla

        logger.info("Dosya baÅŸarÄ±yla yÃ¼klendi ve temizlendi. Streamlit arayÃ¼z geÃ§iÅŸi (rerun) tetikleniyor.")
        # BaÅŸarÄ±lÄ± iÅŸlemlerden sonra arayÃ¼zÃ¼n yeniden Ã§izilmesi iÃ§in yeterlidir.
        st.rerun()  

    # DÄ°KKAT: RerunException bloÄŸu ve import satÄ±rÄ± kaldÄ±rÄ±lmÄ±ÅŸtÄ±r.
    # Genel ve kritik olmayan hatalar iÃ§in sadece bu blok yeterlidir.
    except Exception as e:
        logger.exception("Dosya yÃ¼kleme veya veri iÅŸleme sÄ±rasÄ±nda beklenmeyen bir sorun oluÅŸtu.")  
        st.error(f"Genel Hata: Dosya yÃ¼kleme veya veri iÅŸleme sÄ±rasÄ±nda beklenmeyen bir sorun oluÅŸtu. Detay: {type(e).__name__}: {e}")
        # Hata durumunda session state'i temizle
        st.session_state.df_raw = None
        st.stop()

# --- ANA UYGULAMA DÄ°NAMÄ°K SÄ°DEBAR KONTROLÃœ ---
if st.session_state.df_raw is not None:
    
    upload_placeholder.empty()
    df_raw = st.session_state.df_raw
    
    # 1. NAVÄ°GASYON BÃ–LÃœMÃœ
    st.sidebar.header("ğŸ—ºï¸ 1. Uygulama Modeli (Alet Ã‡antasÄ±)")
    page_selection = st.sidebar.radio(
        "Mod SeÃ§imi",
        ["âœ¨ Tekil Aday Analizi", "ğŸ“‹ Toplu Veri Seti Ä°ncelemesi"],
        index=0 if st.session_state.page_selection == "âœ¨ Tekil Aday Analizi" else 1,
        key="page_selector"
    )
    st.session_state.page_selection = page_selection
    
    # 2. DÄ°NAMÄ°K KONTROLLER (SEÃ‡Ä°LEN MODA GÃ–RE DEÄÄ°ÅÄ°R)
    st.sidebar.markdown("---") 

    if page_selection == "âœ¨ Tekil Aday Analizi":
        # --- Tekil Analiz Kontrolleri ---
        st.sidebar.header("ğŸŒŒ 2. Aday SeÃ§imi ve Analiz")
        
        candidate_index = st.sidebar.selectbox(
            label="Analiz Edilecek AdayÄ± SeÃ§in",
            options=list(range(len(df_raw))),
            format_func=lambda i: f"Aday {i+1} (Orijinal SatÄ±r No: {df_raw.index[i] + 1})",
            index=st.session_state.selected_candidate_index
        )
        st.session_state.selected_candidate_index = candidate_index
        
        # Analiz BaÅŸlat Butonu
        if st.sidebar.button('ğŸš€ SeÃ§ili AdayÄ± Tahmin Et ve Yorumla', type="primary", use_container_width=True):
            st.session_state.run_analysis = candidate_index
            st.session_state.show_results = False 
            
        # --- Ã‡alÄ±ÅŸtÄ±rma MantÄ±ÄŸÄ± ---
        if 'run_analysis' in st.session_state and st.session_state.run_analysis == candidate_index:
            run_simulation_animation(candidate_index + 1)
            try:
                prediction, confidence, shap_buffer, raw_data = CLASSIFIER.predict(df_raw, candidate_index)
                st.session_state.last_prediction = (prediction, confidence, shap_buffer, raw_data)
                st.session_state.show_results = True
                st.session_state.run_analysis = -1 
            except RuntimeError as e: 
                st.error(f"Tahmin HatasÄ±: {e}.")
                st.session_state.show_results = False
            except Exception as e:
                st.error(f"Genel Hata: Beklenmeyen bir sorun oluÅŸtu. Detay: {e}")
                st.session_state.show_results = False
                
        # --- HIZLI SONUÃ‡ Ã–ZETÄ° (Sadece Analiz BittiÄŸinde GÃ¶rÃ¼nÃ¼r) ---
        if 'show_results' in st.session_state and st.session_state.show_results:
            prediction, confidence, _, raw_data = st.session_state.last_prediction
            
            st.sidebar.markdown("---")
            st.sidebar.subheader("ğŸ¯ HÄ±zlÄ± Karar Ã–zeti")
            
            color = "#7FE9F0" if "YANLIÅ" not in prediction else "#DC3545" 
            
            st.sidebar.markdown(f"""
            <div style='padding: 10px; border-left: 5px solid {color}; background-color: #171B20; border-radius: 5px;'>
                <p style='margin: 0; font-size: 14px; font-weight: bold; color: {color};'>Nihai Karar: {prediction}</p>
                <p style='margin: 5px 0 0 0; font-size: 16px; font-weight: 900; color: #fff;'>GÃ¼ven: {confidence:.2%}</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Ä°yileÅŸtirme: AdayÄ±n Ä°nceleme Durumunu gÃ¶ster
            current_status = df_raw.loc[df_raw.index[candidate_index], 'Investigation_Status']
            st.sidebar.markdown("---")
            st.sidebar.markdown(f"""
            <div style='padding: 10px; border-left: 5px solid #FF9900; background-color: #171B20; border-radius: 5px;'>
                <p style='margin: 0; font-size: 14px; font-weight: bold; color: #fff;'>Mevcut Ä°nceleme Durumu:</p>
                <p style='margin: 5px 0 0 0; font-size: 16px; font-weight: 900; color: #FF9900;'>{current_status}</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.sidebar.metric("YÄ±ldÄ±z SÄ±caklÄ±ÄŸÄ±", f"{raw_data.get('koi_steff', 0.0):.0f} K")
            st.sidebar.metric(r"Gezegen YarÄ±Ã§apÄ± ($R_{\oplus}$)", f"{raw_data.get('koi_prad', 0.0):.2f}")
            
    
    elif page_selection == "ğŸ“‹ Toplu Veri Seti Ä°ncelemesi":
        # --- Toplu Analiz Filtre Kontrolleri ---
        st.sidebar.header("ğŸ—„ï¸ 2. Veri Filtreleme (Aletler)")
        
        # Filtreleme AracÄ± 1: Periyot AralÄ±ÄŸÄ±
        min_p = df_raw['koi_period'].min()
        max_p = df_raw['koi_period'].max()
        
        # Sadece min ve max'Ä±n farklÄ± olmasÄ± durumunda slider gÃ¶ster
        if min_p < max_p:
            period_range = st.sidebar.slider(
                "YÃ¶rÃ¼nge Periyodu AralÄ±ÄŸÄ± (GÃ¼n)",
                min_value=min_p,
                max_value=max_p,
                value=(st.session_state.period_range[0] if st.session_state.period_range[0] >= min_p else min_p, 
                       st.session_state.period_range[1] if st.session_state.period_range[1] <= max_p else max_p),
                key="period_slider"
            )
            st.session_state.period_range = period_range
        else:
            st.session_state.period_range = (min_p, max_p)
            
        # Filtreleme AracÄ± 2: Minimum Skor
        score_threshold = st.sidebar.slider(
            "Minimum Kepler/KOI Skoru",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.score_threshold,
            step=0.01,
            key="score_slider"
        )
        st.session_state.score_threshold = score_threshold
        
        # Ä°yileÅŸtirme: Filtreleme AracÄ± 3: Ä°nceleme Durumu Filtresi (Yeni)
        status_filter = st.sidebar.multiselect(
            "Ä°nceleme Durumu Filtresi",
            options=INVESTIGATION_STATUS_OPTIONS,
            default=st.session_state.get('status_filter', INVESTIGATION_STATUS_OPTIONS),
            key="status_filter_multiselect"
        )
        st.session_state.status_filter = status_filter
        
        st.sidebar.markdown("---")
        
    # --- Veri Temizleme Raporu (Her zaman aÃ§Ä±lÄ±p kapanabilir) ---
    if st.session_state.validation_issues and len(st.session_state.validation_issues) > 1:
        with st.sidebar.expander("Temizleme ve Validasyon Raporu"):
            st.warning(st.session_state.validation_issues[0]) 
            for issue in st.session_state.validation_issues[1:]:
                 st.write(f"- {issue}")

    # --- Sayfa YÃ¶nlendirme ---
    if page_selection == "âœ¨ Tekil Aday Analizi":
        main_prediction_page()
    elif page_selection == "ğŸ“‹ Toplu Veri Seti Ä°ncelemesi":
        collective_analysis_page()
