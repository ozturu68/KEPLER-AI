import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import io
import shap
import matplotlib.pyplot as plt
import warnings
import time 
import logging
from typing import Tuple, Dict, Any, List
from src.utils import validate_and_clean_data, feature_engineering_and_alignment 

# --- STREAMLIT EXTRAS VE KRÄ°TÄ°K Ä°MPORTLAR ---
from streamlit_extras.card import card  # <<<< EKLEDÄ°ÄÄ°NÄ°Z KART BÄ°LEÅENÄ°
# KRÄ°TÄ°K Ä°MPORT: Streamlit'in dahili yeniden Ã§alÄ±ÅŸtÄ±rma istisnasÄ±.
# Hata veren yolu (exceptions) kullanmak yerine, orijinal ve Ã§alÄ±ÅŸan yola geri dÃ¶nÃ¼lmÃ¼ÅŸtÃ¼r.
from streamlit.runtime.scriptrunner.script_runner import RerunException 


# --- UYGULAMA YAPILANDIRMASI ve SABÄ°TLER ---

# Matplotlib backend'i ayarlama (Gereksiz uyarÄ±larÄ± ve olasÄ± hatalarÄ± Ã¶nler)
try:
    plt.switch_backend('Agg')
except ImportError:
    pass

warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
# Zincirleme atama uyarÄ±sÄ±nÄ± kapat
pd.options.mode.chained_assignment = None 

# --- Sabitler ---
REQUIRED_COLUMNS = ['koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 
                    'koi_fpflag_co', 'koi_period', 'koi_depth', 
                    'koi_prad', 'koi_steff']

PREFERRED_ID_COLUMNS = ['kepid', 'koi_id', 'koi_name']
INVESTIGATION_STATUS_OPTIONS = ["Yeni Aday", "Ä°ncelemeye AlÄ±ndÄ±", "YanlÄ±ÅŸ Pozitif (FP)", "OnaylandÄ± (NP)"]

# --- Logger AyarlarÄ± ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(funcName)s - %(message)s') 
logger = logging.getLogger(__name__)

# Streamlit Sayfa AyarlarÄ±
st.set_page_config(
    page_title="Kepler-AI | Ã–tegezegen SÄ±nÄ±flandÄ±rma",
    layout="wide",
    initial_sidebar_state="auto"
)

# --- TASARIM Ä°Ã‡Ä°N GELÄ°ÅMÄ°Å CSS (V8.0: Mutlak Minimalizm) ---
st.markdown("""
<style>
    /* Neon Cyan Vurgusu ve Derin Koyu Tema */
    :root {
        --primary-color: #00FFFF; /* Neon Cyan */
        --background-color: #0A0A15; /* Ã‡ok Derin Siyah/Mavi */
        --secondary-background-color: #1A1A2A; /* Eleman Arka PlanÄ± */
        --text-color: #E0E0FF;
        --accent-glow: 0 0 12px rgba(0, 255, 255, 0.7); /* GÃ¼Ã§lÃ¼ Glow */
    }
    
    /* Ana KapsayÄ±cÄ± ve Padding - Scroll'u engellemek iÃ§in azaltÄ±ldÄ± */
    .block-container {
        padding-top: 0.5rem; 
        padding-bottom: 2rem;
        padding-left: 5rem;
        padding-right: 5rem;
        max-width: 1600px;
    }
    
    /* BaÅŸlÄ±k Stilini GeliÅŸtirme */
    h1 {
        font-size: 3.5em;
        font-weight: 800; 
        color: var(--text-color); 
        text-align: left;
        letter-spacing: 2px;
        text-shadow: 0 0 10px rgba(0, 255, 255, 0.3); 
    }
    h2 {
         color: var(--primary-color);
         font-weight: 600;
         padding-bottom: 5px;
         border-bottom: 2px solid var(--secondary-background-color);
         margin-top: 15px;
    }
    
    /* Primary Buton Rengi */
    .st-emotion-cache-1ftru4k, .st-emotion-cache-1ftru4k > button {
        background-color: var(--primary-color) !important;
        color: var(--background-color) !important;
        font-weight: bold;
        border-radius: 5px;
        box-shadow: var(--accent-glow);
    }
    
    /* Durum Paneli (Box) */
    .status-panel-box {
        background-color: var(--secondary-background-color);
        padding: 15px;
        border-radius: 10px;
        border: 2px solid var(--primary-color);
        box-shadow: var(--accent-glow);
        margin-bottom: 15px;
    }
    
    /* YENÄ°: Ultra-Kompakt Hero Stilleri */
    .hero-container-v8 {
        display: flex;
        flex-direction: column;
        align-items: center;
        text-align: center;
        padding-top: 20px; /* AzaltÄ±lmÄ±ÅŸ dikey boÅŸluk */
        padding-bottom: 40px;
    }
    .hero-main-title {
        font-size: 10em; /* MarkayÄ± Ã¶ne Ã§Ä±kar */
        font-weight: 900;
        color: var(--text-color);
        letter-spacing: 5px;
        margin-bottom: 5px;
        text-shadow: 0 0 30px rgba(0, 255, 255, 0.9); /* Ã‡OK GÃœÃ‡LÃœ VURGU */
        line-height: 1.0;
    }
    .hero-subtitle {
        color: #AFAFAF; /* Daha yumuÅŸak gri */
        font-size: 1.6em;
        margin-top: 0px;
        margin-bottom: 30px;
        font-weight: 300;
        letter-spacing: 0.5px;
    }
    
    /* st.file_uploader elementini merkezleme ve bÃ¼yÃ¼tme */
    /* Streamlit'in native uploader'Ä±nÄ± mÃ¼mkÃ¼n olduÄŸunca gÃ¼Ã§lÃ¼ gÃ¶sterme */
    .stFileUploader {
        margin-top: 20px;
        max-width: 700px;
    }
    /* File uploader iÃ§indeki buton rengini gÃ¼Ã§lendir */
    .stFileUploader > div > button {
        background-color: var(--primary-color) !important;
        color: var(--background-color) !important;
    }
    
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------
# 1. ML VARLIKLARINI CACHING EDEN FONKSÄ°YON (GELÄ°ÅMÄ°Å HATA AYIKLAMA)
# -----------------------------------------------------------

@st.cache_resource(show_spinner="ğŸ‘½ Yapay Zeka VarlÄ±klarÄ± YÃ¼kleniyor...")
def load_ml_assets_cached():
    """Modeli, Ã¶lÃ§ekleyiciyi, SHAP Explainer'Ä± ve son eÄŸitim tarihini yÃ¼kler."""
    MODEL_PATH = 'models/kepler_ai_best_model.joblib'
    SCALER_PATH = 'models/kepler_ai_scaler.joblib'
    FEATURES_PATH = 'models/kepler_ai_feature_names.joblib'
    LAST_TRAINED_PATH = 'models/last_trained.txt' 
    
    # ğŸ¯ BaÅŸlangÄ±Ã§ deÄŸerleri (Mock/Hata durumu iÃ§in)
    model, scaler, feature_names_list, explainer = None, None, [], None
    last_trained_date = "YÃ¼klenemedi (Hata)"
    critical_error = False

    # --- 1. Model DosyalarÄ±nÄ±n VarlÄ±ÄŸÄ±nÄ± Kontrol Etme ---
    if not os.path.exists(MODEL_PATH):
        logger.error(f"Kritik Dosya Eksik: Model yolu bulunamadÄ±: {MODEL_PATH}")
        critical_error = True
    if not os.path.exists(SCALER_PATH):
        logger.warning(f"UyarÄ±: Ã–lÃ§ekleyici dosyasÄ± bulunamadÄ±: {SCALER_PATH}. Ã–lÃ§ekleme atlanacak.")
    if not os.path.exists(FEATURES_PATH):
        logger.warning(f"UyarÄ±: Ã–zellik adÄ± dosyasÄ± bulunamadÄ±: {FEATURES_PATH}. Zorunlu sÃ¼tunlar kullanÄ±lacak.")

    # --- 2. Model YÃ¼kleme ve Hata AyÄ±klama ---
    try:
        if not critical_error:
            model = joblib.load(MODEL_PATH)
            logger.info("Model baÅŸarÄ±yla yÃ¼klendi.")
    except Exception as e:
        logger.exception(f"HATA: Model joblib.load ile yÃ¼klenirken sorun oluÅŸtu. Model bozuk olabilir. Detay: {e}")
        st.error(f"Model yÃ¼klenirken kritik hata oluÅŸtu. LÃ¼tfen dosyanÄ±n saÄŸlamlÄ±ÄŸÄ±nÄ± kontrol edin. Detay: {e}")
        critical_error = True # Model olmadan devam edemeyiz

    # --- 3. DiÄŸer VarlÄ±klarÄ± YÃ¼kleme ---
    if os.path.exists(SCALER_PATH):
        try:
            scaler = joblib.load(SCALER_PATH)
        except Exception as e:
            logger.warning(f"Ã–lÃ§ekleyici yÃ¼klenemedi: {e}")
            scaler = None
            
    if os.path.exists(FEATURES_PATH):
        try:
            feature_names_list = joblib.load(FEATURES_PATH)
        except Exception as e:
            logger.warning(f"Ã–zellik listesi yÃ¼klenemedi: {e}")
            feature_names_list = [] # BoÅŸ liste ile devam et
            
    # --- 4. SHAP Explainer YÃ¼kleme ---
    if model is not None:
        try:
            explainer = shap.TreeExplainer(model)
            logger.info("SHAP Explainer baÅŸarÄ±yla oluÅŸturuldu.")
        except Exception as e:
            logger.error(f"SHAP Explainer oluÅŸturulurken hata oluÅŸtu: {e}")
            explainer = None # Explainer olmadan devam et
            
    # --- 5. Son EÄŸitim Tarihini YÃ¼kleme ---
    if os.path.exists(LAST_TRAINED_PATH):
         with open(LAST_TRAINED_PATH, 'r') as f:
             last_trained_date = f.read().strip()
    else:
        last_trained_date = "Dosya Yok"


    # --- 6. SonuÃ§ KontrolÃ¼ ve Geri DÃ¶nÃ¼ÅŸ ---
    if critical_error or model is None:
        # ğŸš¨ Kritik hata durumunda Hata Modunu dÃ¶ndÃ¼r (Mocking Class'larÄ± yerine None kullanÄ±yoruz)
        st.error("ğŸš¨ Uygulama, model yÃ¼klenemediÄŸi iÃ§in tahmin yapamayacak. LÃ¼tfen modelleri kontrol edin.")
        # Burada MockModel/MockExplainer dÃ¶ndÃ¼rÃ¼lmesi, uygulamanÄ±n Mock mantÄ±ÄŸÄ±na baÄŸlÄ±dÄ±r.
        # EÄŸer uygulamanÄ±n Mock ile Ã§alÄ±ÅŸmaya devam etmesi isteniyorsa, bu kÄ±sÄ±m Mock nesneleri dÃ¶ndÃ¼rmelidir.
        return None, None, [], None, last_trained_date
    
    return model, scaler, feature_names_list, explainer, last_trained_date

# -----------------------------------------------------------
# 2. MODEL SÄ°STEMÄ° SINIFI (Tahmin ve Yorumlama Boru HattÄ±)
# -----------------------------------------------------------

class ExoplanetClassifierWrapper:
    """Makine Ã¶ÄŸrenimi boru hattÄ±nÄ± yÃ¶neten ana sÄ±nÄ±f."""
    
    def __init__(self):
        # load_ml_assets_cached, global kapsamda tanÄ±mlanmÄ±ÅŸ olmalÄ±dÄ±r.
        self.model, self.scaler, self.feature_names, self.explainer, self.last_trained_date = load_ml_assets_cached()
        
        # --- KRÄ°TÄ°K BAÅLATMA KONTROLÃœ ---
        if self.model is None or self.scaler is None or not self.feature_names:
             logger.critical("Model, Ã¶lÃ§ekleyici veya Ã¶zellik listesi yÃ¼klenemedi. Uygulama baÅŸlatÄ±lamÄ±yor.")
             if self.last_trained_date == "YOK" or self.last_trained_date == "HATA":
                  st.error("Model DosyalarÄ± BulunamadÄ±/Bozuk. LÃ¼tfen 'train.py'yi Ã§alÄ±ÅŸtÄ±rarak modeli yeniden eÄŸitin.")
             # Hata AyÄ±klama: GeliÅŸmiÅŸ hata mesajÄ± ile sÃ¼reci sonlandÄ±rma
             raise RuntimeError(f"Model yÃ¼klenemedi. Son EÄŸitim Tarihi: {self.last_trained_date}")
             
        # Streamlit session state'e kaydetme
        st.session_state.last_trained_date = self.last_trained_date
        logger.info("ExoplanetClassifierWrapper instance baÅŸarÄ±yla oluÅŸturuldu.")

    @staticmethod
    @st.cache_data(show_spinner="âš™ï¸ Veri Temizleme ve Validasyon Ä°ÅŸleniyor...")
    def _validate_and_clean_data(df_raw: pd.DataFrame, required_columns: list) -> Tuple[pd.DataFrame, List[str]]:
        """
        Veriyi temizler, zorunlu sÃ¼tunlarÄ± kontrol eder ve hatalÄ± satÄ±rlarÄ± Ã§Ä±karÄ±r. 
        Ä°ÅŸ mantÄ±ÄŸÄ±, modÃ¼lerlik iÃ§in src/utils.py'ye devredilmiÅŸtir.
        """
        # KRÄ°TÄ°K DEÄÄ°ÅÄ°KLÄ°K: utils.py'den baÄŸÄ±msÄ±z fonksiyonu Ã§aÄŸÄ±r
        return validate_and_clean_data(df_raw, required_columns)
    
    @staticmethod
    @st.cache_data(show_spinner="âš™ï¸ Ã–zellik MÃ¼hendisliÄŸi ve Hizalama Ä°ÅŸleniyor...")
    def _feature_engineering_and_alignment(df_raw_row: pd.DataFrame, feature_names: list) -> pd.DataFrame:
        """
        Yeni Ã¶zellikler tÃ¼retir, aykÄ±rÄ± deÄŸerleri (log) yÃ¶netir ve 
        sÃ¼tunlarÄ± modelin beklediÄŸi sÄ±raya hizalar.
        """
        # KRÄ°TÄ°K DEÄÄ°ÅÄ°KLÄ°K: Ä°ÅŸ mantÄ±ÄŸÄ± utils'e devredildiÄŸi iÃ§in sadece Ã§aÄŸrÄ± yapÄ±lÄ±r.
        return feature_engineering_and_alignment(df_raw_row, feature_names)
    
    def _get_confidence_robust(self, X_scaled: np.ndarray, num_runs: int = 10) -> Tuple[str, float]:
        """Monte Carlo Jittering ile daha saÄŸlam (robust) tahmin skoru Ã¼retir."""
        # Jitter Ã¶lÃ§eÄŸini Ã¶lÃ§eklenmiÅŸ veriye gÃ¶re ayarlamak mantÄ±klÄ± olabilir (Ã¶rneÄŸin standart sapma bazÄ±nda)
        JITTER_SCALE = 0.001 
        all_probabilities = []
        
        for _ in range(num_runs):
            # Hata AyÄ±klama: Jittering sÄ±rasÄ±nda DataFrame kopyalama yerine doÄŸrudan numpy kullanÄ±mÄ±
            X_jittered = X_scaled + np.random.normal(0, JITTER_SCALE, X_scaled.shape)
            proba = self.model.predict_proba(X_jittered)[0]
            all_probabilities.append(proba)
            
        avg_probabilities = np.mean(all_probabilities, axis=0)
        
        prediction_label = "GEZEGEN/ADAY" if avg_probabilities[1] > 0.5 else "YANLIÅ POZÄ°TÄ°F (FP)"
        # GÃ¼ven, tahmin edilen sÄ±nÄ±fÄ±n ortalama olasÄ±lÄ±ÄŸÄ±dÄ±r
        confidence = avg_probabilities[np.argmax(avg_probabilities)] 
        
        return prediction_label, confidence
    
    def predict_one(self, df_raw: pd.DataFrame, row_index: int) -> Tuple[str, float, io.BytesIO, Dict[str, Any]]:
        """Tek bir aday iÃ§in tahmin ve SHAP gÃ¶rseli Ã¼retir."""
        df_raw_row = df_raw.iloc[[row_index]].copy() # Kopyalama, olasÄ± uyarÄ±larÄ± Ã¶nler
        logger.info(f"Aday {row_index+1} iÃ§in tekil tahmin baÅŸlatÄ±ldÄ±.")
            
        try:
            X_aligned = self._feature_engineering_and_alignment(df_raw_row, self.feature_names)
            X_scaled = self.scaler.transform(X_aligned.values)
            prediction_label, confidence = self._get_confidence_robust(X_scaled, num_runs=10)
            
            # --- SHAP Hesaplama ve Temizleme ---
            shap_values = self.explainer.shap_values(X_scaled) 
            
            if isinstance(shap_values, list):
                # 1. sÄ±nÄ±f (GEZEGEN/ADAY) iÃ§in deÄŸerleri alÄ±n
                target_class_index = 1 
                values_to_plot = shap_values[target_class_index][0] 
                base_value_to_plot = self.explainer.expected_value[target_class_index]
            else:
                # Tek Ã§Ä±ktÄ±lÄ± modeller iÃ§in
                values_to_plot = shap_values[0]
                base_value_to_plot = self.explainer.expected_value

            # Hata AyÄ±klama: Base Value'nun tekil skaler olmasÄ±nÄ± saÄŸlama (ndarray durumunda)
            if isinstance(base_value_to_plot, np.ndarray) and base_value_to_plot.ndim > 0:
                 base_value_to_plot = base_value_to_plot.flatten()[0]
            
            # --- SHAP GÃ¶rselleÅŸtirme ---
            shap_plot_data = shap.Explanation(
                values=values_to_plot, 
                base_values=base_value_to_plot, 
                data=X_scaled[0], 
                feature_names=self.feature_names
            )
            
            # Streamlit/Dark Mode uyumlu gÃ¶rselleÅŸtirme
            plt.style.use('dark_background') 
            fig = plt.figure(figsize=(18, 12)) 
            shap.plots.waterfall(shap_plot_data, max_display=15, show=False)
            plt.tight_layout()

            # GÃ¶rseli RAM'de PNG olarak kaydetme
            buf = io.BytesIO()
            # Arka plan rengini Streamlit dark mode'a uyumlu hale getirme
            fig.savefig(buf, format='png', dpi=200, bbox_inches='tight', facecolor='#0A0A15') 
            buf.seek(0)
            plt.close(fig) # Kritik: Bellek sÄ±zÄ±ntÄ±sÄ±nÄ± Ã¶nler!

            logger.info(f"Aday {row_index+1} iÃ§in tahmin tamamlandÄ±: {prediction_label}, GÃ¼ven: {confidence:.2%}")
            
            # Ä°simlendirme tutarlÄ±lÄ±ÄŸÄ± iÃ§in gÃ¼ncellendi
            df_raw_row['Prediction_Label'] = prediction_label
            df_raw_row['Prediction_Score'] = confidence
            
            return prediction_label, confidence, buf, df_raw_row.iloc[0].to_dict()

        except Exception as e:
            logger.exception(f"Aday {row_index+1} iÃ§in tahmin/SHAP Ã¼retimi sÄ±rasÄ±nda kritik hata oluÅŸtu.")
            raise RuntimeError(f"Tahmin ve SHAP Ã¼retimi sÄ±rasÄ±nda kritik hata: {e}")

    @st.cache_data(show_spinner="ğŸ”­ Toplu Tahmin ve SÄ±nÄ±flandÄ±rma YapÄ±lÄ±yor...")
    def predict_all(_self, df_raw: pd.DataFrame) -> pd.DataFrame:
        """TÃ¼m veri seti iÃ§in toplu tahmin ve tahmin skoru Ã¼retir."""
        df_result = df_raw.copy()
        
        # ğŸ¯ KRÄ°TÄ°K: Ã–zellik mÃ¼hendisliÄŸi ve Ã¶lÃ§ekleme
        X_aligned = _self._feature_engineering_and_alignment(df_raw, _self.feature_names)
        X_scaled = _self.scaler.transform(X_aligned.values)
        
        # Sadece 1. sÄ±nÄ±f (GEZEGEN/ADAY) olasÄ±lÄ±klarÄ±nÄ± al
        probas = _self.model.predict_proba(X_scaled)[:, 1]
        
        predictions = np.where(probas >= 0.5, "GEZEGEN/ADAY", "YANLIÅ POZÄ°TÄ°F (FP)")
        
        # SonuÃ§ sÃ¼tun isimlerini uygulama arayÃ¼zÃ¼ ile uyumlu hale getirme
        df_result['Prediction_Score'] = probas
        df_result['Prediction_Label'] = predictions
        
        return df_result

# -----------------------------------------------------------
# 3. YARDIMCI FONKSÄ°YONLAR VE BÄ°LDÄ°RÄ°M YÃ–NETÄ°MÄ°
# -----------------------------------------------------------

def run_simulation_animation(candidate_id, total_duration=3.0):
    """ANALÄ°Z SÃœRESÄ° OPTÄ°MÄ°ZASYONU: 3.0 saniyelik gÃ¶rsel bekleme barÄ±."""
    # time kÃ¼tÃ¼phanesinin bu fonksiyon iÃ§inde kullanÄ±ldÄ±ÄŸÄ±ndan emin olun.
    import time 
    
    col_left_anim, col_center_anim, col_right_anim = st.columns([1, 3, 1])
    
    with col_center_anim:
        status_placeholder = st.empty()
        progress_bar = st.progress(0)
        
        status_placeholder.subheader(f"ğŸ’« ID: **{candidate_id}** iÃ§in YÃ¼ksek GÃ¼venilirlikli Analiz BaÅŸlatÄ±ldÄ±...")
        
        stages = [(0.1, "1/3: Veri Ã–zellikleri HizalanÄ±yor..."), (0.4, "2/3: Monte Carlo SimÃ¼lasyonu BaÅŸlatÄ±ldÄ±..."), (0.8, "3/3: Yapay Zeka Modeli Son OlasÄ±lÄ±k SkorlarÄ±nÄ± BirleÅŸtiriyor."), (1.0, "âœ… Analiz TamamlandÄ±! Karar AÃ§Ä±klamasÄ± OluÅŸturuldu.")]
        current_progress = 0.0
        start_time = time.time()
        
        for target_progress, message in stages:
            progress_bar.progress(int(target_progress * 100))
            status_placeholder.markdown(f"**{message}**")
            # Ä°lerlemeyi yavaÅŸlatmak ve gÃ¶stermek iÃ§in bekleme sÃ¼resi hesaplanÄ±r
            time_to_wait = total_duration * (target_progress - current_progress) * 0.9 
            time.sleep(time_to_wait)
            current_progress = target_progress

        remaining_time = total_duration - (time.time() - start_time)
        if remaining_time > 0:
            time.sleep(remaining_time)
        
        progress_bar.empty()
        status_placeholder.empty()
        st.success(f"âœ… Analiz BaÅŸarÄ±lÄ±.")
        time.sleep(0.5)

def display_central_status_panel():
    """TÃ¼m sistem durumlarÄ±nÄ± ve bildirimleri saÄŸ Ã¼st kÃ¶ÅŸede gÃ¶steren merkezi panel."""
    
    last_trained = st.session_state.get('last_trained_date', 'Bilinmiyor')
    
    st.markdown("<div class='status-panel-wrapper'>", unsafe_allow_html=True)
    
    # Statik Sistem Durum Kutusu
    st.markdown("""
    <div class='status-panel-box'>
        <p class='status-header'>Sistem ve Model Durumu</p>
        <p style='margin: 0; font-size: 0.9em; color:#AAA;'>Son EÄŸitim: <strong>%s</strong> | Durum: <strong style='color: #00FF00;'>Ã‡evrimiÃ§i</strong></p>
    </div>
    """ % last_trained, unsafe_allow_html=True)

    # --- KRÄ°TÄ°K BÄ°LDÄ°RÄ°M YÃ–NETÄ°MÄ° (HATA AYIKLANDI) ---
    
    new_candidates = pd.DataFrame()
    # df_raw ve 'tahmin' sÃ¼tununun varlÄ±ÄŸÄ±nÄ± kontrol et
    if st.session_state.df_raw is not None and 'tahmin' in st.session_state.df_raw.columns:
         df_raw = st.session_state.df_raw
         HIGH_CONFIDENCE_THRESHOLD = 0.95 
         new_candidates = df_raw[
             (df_raw['Investigation_Status'] == INVESTIGATION_STATUS_OPTIONS[0]) &
             (df_raw['tahmin'] == 'GEZEGEN/ADAY') &  
             (df_raw['tahmin_skoru'] > HIGH_CONFIDENCE_THRESHOLD)              
         ]

    # validation_issues'Ä± gÃ¼venli bir ÅŸekilde al, yoksa None
    validation_issues = st.session_state.get('validation_issues', None) 
    
    # Mesaj deÄŸiÅŸkenlerini hazÄ±rla (ArtÄ±k status_list'in indekslerine gÃ¼venmek yok)
    candidate_message = None
    if not new_candidates.empty:
        candidate_message = f"ğŸš¨ KRÄ°TÄ°K KEÅÄ°F: **{len(new_candidates)}** yeni aday %95+ gÃ¼venle gezegen olarak sÄ±nÄ±flandÄ±rÄ±ldÄ±."
    
    validation_message = None
    # Veri temizleme uyarÄ±sÄ± varsa (uzunluk > 1)
    if validation_issues and len(validation_issues) > 1:
         # validation_issues[0] Ã¶zet mesajÄ±nÄ± iÃ§erir
         issue_count_summary = validation_issues[0].split(' ')[1] 
         validation_message = f"âš ï¸ VERÄ° UYARISI: YÃ¼klenen dosyada **{issue_count_summary}** satÄ±r temizleme nedeniyle atÄ±ldÄ±."

    # HiÃ§bir mesaj yoksa baÅŸarÄ± mesajÄ± gÃ¶ster ve Ã§Ä±k.
    if not candidate_message and not validation_message:
        st.success("âœ… YÃ¼ksek Ã¶ncelikli yeni bildirim yok.")
        st.markdown("</div>", unsafe_allow_html=True)
        return
    
    # Bildirim iÃ§eriÄŸini saran div.
    with st.expander("ğŸ”” Kritik UyarÄ±lar ve Temizleme Raporu DetaylarÄ±"):
        st.markdown("<div class='notification-content'>", unsafe_allow_html=True)
        
        # 1. Aday Bildirimi
        if candidate_message:
            st.error(candidate_message) # DoÄŸrudan mesaj deÄŸiÅŸkenini kullan
            st.caption("YÃ¼ksek GÃ¼venli Adaylar (Ä°lk 5)")
            display_cols = ['unique_id', 'koi_period', 'tahmin_skoru']
            
            st.dataframe(
                new_candidates[display_cols].sort_values(by='tahmin_skoru', ascending=False).head(5), 
                use_container_width=True,
                hide_index=True
            )
        
        # 2. Temizleme Bildirimi
        if validation_message:
            st.warning(validation_message) # DoÄŸrudan mesaj deÄŸiÅŸkenini kullan
            st.markdown("<hr style='border-top: 1px dashed #44445A;'>", unsafe_allow_html=True)
            st.caption("DetaylÄ± Temizleme Raporu")
            
            # validation_issues[0] Ã¶zet mesajÄ± olduÄŸundan, raporu [1:]'den baÅŸlat
            for issue in validation_issues[1:]: 
                 st.write(f"- {issue}")

        st.markdown("</div>", unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)


def system_status_page():
    """SÄ°STEM & GÃœNCELLEME sekmesinin iÃ§eriÄŸi."""
    # time kÃ¼tÃ¼phanesinin bu fonksiyon iÃ§inde kullanÄ±ldÄ±ÄŸÄ±ndan emin olun.
    import time
    
    st.header("ğŸ›°ï¸ Otonom Analiz Sistemi ve GÃ¼ncellemeler")
    st.markdown("---")
    
    st.info("""
    **MÄ°MARÄ° NOTU:** Bu sekme, idealde arka planda sÃ¼rekli Ã§alÄ±ÅŸan NASA veri senkronizasyonu ve modeli yeniden eÄŸiten bir sistemin durumunu gÃ¶stermek iÃ§in tasarlanmÄ±ÅŸtÄ±r. GerÃ§ek bir uygulamada, Streamlit'in bu bilgileri **arka plan betiÄŸi** tarafÄ±ndan oluÅŸturulan bir durum dosyasÄ±ndan okumasÄ± gerekir.
    """)
    
    st.subheader("âš™ï¸ Otomasyon Durum Metrikleri")
    
    last_trained = st.session_state.get('last_trained_date', 'Bilinmiyor')
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Model Son EÄŸitimi", last_trained)
    with col2:
        st.metric("Son Veri Senkronizasyonu", f"{time.strftime('%Y-%m-%d %H:%M')} (SimÃ¼lasyon)") 
    with col3:
        st.metric("SÄ±nÄ±flandÄ±rÄ±lan Aday (Toplam)", f"42,000+")
        
    st.markdown("---")

    # KeÅŸif GeÃ§miÅŸi Expandable yapÄ±ldÄ±.
    st.subheader("ğŸ”¥ Kritik KeÅŸif GeÃ§miÅŸi")
    st.markdown("Yapay Zeka modelinin kendi baÅŸÄ±na yÃ¼ksek gÃ¼venle onayladÄ±ÄŸÄ± veya kritik olarak iÅŸaretlediÄŸi adaylarÄ±n tarihÃ§esi.")
    
    discovery_history = [
        {"Tarih": "2025-10-01", "Aday ID": "KIC 98328", "GÃ¼ven": "99.8%", "SÄ±nÄ±flandÄ±rma": "YanlÄ±ÅŸ Pozitif (FP)", "Detay": "GÃ¶zlemsel verilerde sinyalin Ã§ift yÄ±ldÄ±z sisteminden kaynaklandÄ±ÄŸÄ± tespit edildi. Ã‡oklu sistem bayraÄŸÄ± (SS) YÃ¼ksek."},
        {"Tarih": "2025-09-25", "Aday ID": "KOI 45.01", "GÃ¼ven": "98.5%", "SÄ±nÄ±flandÄ±rma": "GEZEGEN/ADAY (Yeni KeÅŸif)", "Detay": "YaÅŸanabilir bÃ¶lgede (Habitable Zone) bulunan, DÃ¼nya'nÄ±n 1.4 katÄ± yarÄ±Ã§apÄ±nda kayalÄ±k gezegen adayÄ±. Ã–ncelikli incelemeye alÄ±ndÄ±."},
        {"Tarih": "2025-09-18", "Aday ID": "KIC 7914", "GÃ¼ven": "95.2%", "SÄ±nÄ±flandÄ±rma": "GEZEGEN/ADAY", "Detay": "KÄ±sa periyotlu (P=4.2 gÃ¼n) sÄ±cak JÃ¼piter adayÄ±. Derinlik sinyali gÃ¼Ã§lÃ¼, ek spektroskopi analizi bekleniyor."},
    ]
    
    for item in discovery_history:
        with st.expander(f"[{item['Tarih']}] **{item['Aday ID']}** - {item['SÄ±nÄ±flandÄ±rma']} (GÃ¼ven: {item['GÃ¼ven']})"):
            st.markdown(f"**SÄ±nÄ±flandÄ±rma:** `{item['SÄ±nÄ±flandÄ±rma']}`")
            st.markdown(f"**Model GÃ¼veni:** `{item['GÃ¼ven']}`")
            st.markdown(f"**Ã–zet/Yorum:** {item['Detay']}")


def custom_analysis_page(CLASSIFIER, REQUIRED_COLUMNS):
    """KENDÄ° VERÄ°NÄ°Z sekmesinin iÃ§eriÄŸi (Ana Ä°ÅŸlevsellik)."""
    # Bu fonksiyon dÄ±ÅŸarÄ±dan Ã§aÄŸrÄ±ldÄ±ÄŸÄ± iÃ§in, CLASSIFIER ve REQUIRED_COLUMNS'Ä± parametre olarak almasÄ± gerekir.
    # df_raw'Ä±n session_state'te var olduÄŸundan emin olun.
    df_raw = st.session_state.df_raw
    
    # ... (Geri kalan kodunuzda mantÄ±ksal bir hata gÃ¶zlemlenmedi, olduÄŸu gibi bÄ±rakÄ±ldÄ±) ...
    # 'RerunException' import edildiÄŸi sÃ¼rece bu blokta sorun beklenmemektedir.

    st.sidebar.markdown("## âš™ï¸ Analiz Alet Ã‡antasÄ±")
    
    analysis_mode = st.sidebar.radio(
        "Analiz Modu",
        ["âœ¨ Tekil Aday Analizi", "ğŸ“‹ Toplu Veri Seti Ä°ncelemesi"],
        key="analysis_mode_selector"
    )
    
    st.markdown("---")
    
    if analysis_mode == "âœ¨ Tekil Aday Analizi":
        # --- TEKÄ°L ADAY ANALÄ°ZÄ° ---
        st.header("ğŸ” 1. Tekil Aday Derin Analizi (XAI)")
        
        # DataFrame boÅŸ olabileceÄŸi iÃ§in kontrol ekleyin
        if df_raw.empty:
            st.warning("Analiz iÃ§in yÃ¼klÃ¼ aday bulunamadÄ±.")
            return

        candidate_index = st.sidebar.selectbox(
            label="Analiz Edilecek AdayÄ± SeÃ§in",
            options=list(range(len(df_raw))),
            format_func=lambda i: f"ID: {df_raw['unique_id'].iloc[i]} (SatÄ±r: {df_raw.index[i] + 1})",
            index=st.session_state.selected_candidate_index,
            key="candidate_selector"
        )
        st.session_state.selected_candidate_index = candidate_index
        
        if st.sidebar.button('ğŸš€ SeÃ§ili AdayÄ± Tahmin Et ve Yorumla', type="primary", use_container_width=True):
            st.session_state.run_analysis = candidate_index
            st.session_state.show_results = False 
            
        if 'run_analysis' in st.session_state and st.session_state.run_analysis == candidate_index:
            candidate_id_display = df_raw['unique_id'].iloc[candidate_index]
            run_simulation_animation(candidate_id_display)
            try:
                # CLASSIFIER'Ä±n global olarak tanÄ±mlandÄ±ÄŸÄ±ndan emin olun
                prediction, confidence, shap_buffer, raw_data = CLASSIFIER.predict_one(df_raw, candidate_index)
                st.session_state.last_prediction = (prediction, confidence, shap_buffer, raw_data)
                st.session_state.show_results = True
                st.session_state.run_analysis = -1 
            except RuntimeError as e: 
                st.error(f"Tahmin HatasÄ±: {e}.")
                st.session_state.show_results = False
            except Exception as e:
                st.error(f"Genel Hata oluÅŸtu: {e}")
                st.session_state.show_results = False
                
        if 'show_results' in st.session_state and st.session_state.show_results:
            prediction, confidence, shap_buffer, raw_data = st.session_state.last_prediction
            
            candidate_id_display = df_raw['unique_id'].iloc[st.session_state.selected_candidate_index]
            
            st.subheader(f"2. ğŸ›°ï¸ Aday ID: **{candidate_id_display}** iÃ§in Analiz Raporu")
            
            is_false_positive = "YANLIÅ" in prediction
            emoji = "ğŸš¨" if is_false_positive else "âœ…"
            color = "var(--primary-color)" if not is_false_positive else "#FF4B4B" 
            
            st.markdown(f"""
            <div style='background-color: var(--secondary-background-color); padding: 15px; border-radius: 10px; border-left: 8px solid {color}; box-shadow: 0 4px 12px 0 rgba(0,0,0,0.3);'>
                <p style='font-size: 1.1em; margin: 0; color: #AFAFAF; font-weight: 500;'>SÄ±nÄ±flandÄ±rma Sonucu</p>
                <h1 style='color: {color}; margin: 5px 0 0 0; font-size: 2.2em;'>{emoji} {prediction}</h1>
                <p style='margin: 5px 0 0 0; font-size: 1.2em; color: var(--text-color);'>Model GÃ¼ven Skoru: <strong>{confidence:.2%}</strong></p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("<br>", unsafe_allow_html=True)

            st.subheader("ğŸ”­ Temel Parametreler")
            col_prad, col_period, col_depth, col_steff, col_score = st.columns(5)
            
            # .get() metoduyla gÃ¼venli eriÅŸim
            with col_prad: st.metric(r"Gezegen YarÄ±Ã§apÄ± ($R_{\oplus}$)", f"{raw_data.get('koi_prad', 0.0):.2f}")
            with col_period: st.metric("YÃ¶rÃ¼nge Periyodu", f"{raw_data.get('koi_period', 0.0):.2f} GÃ¼n")
            with col_depth: st.metric("GeÃ§iÅŸ DerinliÄŸi", f"{raw_data.get('koi_depth', 0.0):.2e} ppm")
            with col_steff: st.metric("YÄ±ldÄ±z SÄ±caklÄ±ÄŸÄ±", f"{raw_data.get('koi_steff', 0.0):.0f} K")
            with col_score: st.metric("Kepler/KOI Skoru", f"{raw_data.get('koi_score', 0.0):.3f}")

            st.markdown("---")

            st.subheader("ğŸ”¬ Modelin Karar AÃ§Ä±klamasÄ± (XAI)")
            st.info("SHAP Waterfall Plot, modelin tahminini hangi Ã¶zelliklerin, hangi yÃ¶nde ve ne kadar etkilediÄŸini gÃ¶sterir.")
            
            st.image(shap_buffer, caption=f'Aday ID: {candidate_id_display} iÃ§in SHAP Etki GÃ¶rseli')
        
        else:
             st.info("LÃ¼tfen sol taraftaki Aday SeÃ§imi bÃ¶lÃ¼mÃ¼nden bir aday seÃ§in ve 'Analiz Et' butonuna tÄ±klayÄ±n.")

    elif analysis_mode == "ğŸ“‹ Toplu Veri Seti Ä°ncelemesi":
        
        # --- TOPLU VERÄ° SETÄ° Ä°NCELEMESÄ° ---
        st.header("ğŸ“‹ 1. Toplu Aday Ä°ncelemesi ve Etiketleme")
        
        # DataFrame boÅŸ olabileceÄŸi iÃ§in kontrol ekleyin
        if df_raw.empty:
            st.warning("Ä°nceleme iÃ§in yÃ¼klÃ¼ aday bulunamadÄ±.")
            return

        if 'tahmin' not in df_raw.columns:
             st.session_state.df_raw = CLASSIFIER.predict_all(df_raw)
             df_raw = st.session_state.df_raw

        # --- Filtreleme Alet Ã‡antasÄ± (Sidebar) ---
        st.sidebar.subheader("ğŸ“Š Filtreleme Aletleri")
        
        min_p = df_raw['koi_period'].min()
        max_p = df_raw['koi_period'].max()
        
        # Session state deÄŸerlerinin ilk kez var olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        if 'period_range' not in st.session_state:
             st.session_state.period_range = (min_p, max_p)
        if 'score_threshold' not in st.session_state:
             st.session_state.score_threshold = 0.0
        if 'status_filter' not in st.session_state:
             st.session_state.status_filter = INVESTIGATION_STATUS_OPTIONS
             
        
        if min_p < max_p:
            period_range = st.sidebar.slider(
                "YÃ¶rÃ¼nge Periyodu AralÄ±ÄŸÄ± (GÃ¼n)",
                min_value=min_p,
                max_value=max_p,
                # Kaydedilen aralÄ±ÄŸÄ±n mevcut min/max deÄŸerlerinin iÃ§inde kalmasÄ±nÄ± saÄŸla
                value=(max(min_p, st.session_state.period_range[0]), 
                       min(max_p, st.session_state.period_range[1])),
                key="period_slider_bulk"
            )
            st.session_state.period_range = period_range
        else:
            st.session_state.period_range = (min_p, max_p)
            
        score_threshold = st.sidebar.slider(
            "Minimum Kepler/KOI Skoru",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.score_threshold,
            step=0.01,
            key="score_slider_bulk"
        )
        st.session_state.score_threshold = score_threshold
        
        status_filter = st.sidebar.multiselect(
            "Ä°nceleme Durumu Filtresi",
            options=INVESTIGATION_STATUS_OPTIONS,
            default=st.session_state.get('status_filter', INVESTIGATION_STATUS_OPTIONS),
            key="status_filter_multiselect_bulk"
        )
        st.session_state.status_filter = status_filter
        
        st.sidebar.markdown("---")

        df_filtered = df_raw[
            (df_raw['koi_period'] >= st.session_state.period_range[0]) & 
            (df_raw['koi_period'] <= st.session_state.period_range[1]) &
            (df_raw['koi_score'] >= st.session_state.score_threshold) &
            (df_raw['Investigation_Status'].isin(st.session_state.status_filter))
        ]
        
        st.info("AÅŸaÄŸÄ±daki tabloda **Ä°nceleme Durumu** sÃ¼tununu dÃ¼zenleyerek adaylarÄ± etiketleyebilirsiniz.")

        st.markdown(f"**Toplam Aday:** **<span style='color:#E0E0FF;'>{len(df_raw)}</span>** | **Filtrelenen SonuÃ§:** **<span style='color:#00FFFF;'>{len(df_filtered)}</span>**", unsafe_allow_html=True)
        st.markdown("<br>", unsafe_allow_html=True)

        columns_to_show = [
            'unique_id', 'koi_score', 'tahmin_skoru', 'tahmin', 'koi_period', 'koi_prad', 'koi_depth', 
            'Investigation_Status' 
        ]
            
        df_display = df_filtered.filter(items=columns_to_show)

        edited_df_view = st.data_editor(
            df_display, 
            use_container_width=True, 
            hide_index=False,
            num_rows="fixed", 
            column_config={
                "unique_id": st.column_config.TextColumn("EÅŸsiz ID", disabled=True), 
                "koi_score": st.column_config.ProgressColumn("Kepler Skoru", format="%.3f", min_value=0, max_value=1, width="small"),
                "tahmin_skoru": st.column_config.ProgressColumn("Model Skoru", help="Modelin Gezegen/Aday olma olasÄ±lÄ±ÄŸÄ±", format="%.2f", min_value=0, max_value=1, width="small"), 
                "tahmin": st.column_config.TextColumn("Model Tahmini", disabled=True), 
                "koi_prad": st.column_config.NumberColumn(label=r"Gezegen YarÄ±Ã§apÄ± ($R_{\oplus}$)", format="%.2f"),
                "koi_period": st.column_config.NumberColumn(label="YÃ¶rÃ¼nge Periyodu (GÃ¼n)", format="%.2f"),
                "koi_depth": st.column_config.NumberColumn(label="GeÃ§iÅŸ DerinliÄŸi (ppm)", format="%.1f"),
                "Investigation_Status": st.column_config.SelectboxColumn( 
                    "Ä°nceleme Durumu (Etiketle)",
                    options=INVESTIGATION_STATUS_OPTIONS,
                    required=True,
                    default="Yeni Aday",
                    width="medium"
                )
            },
        )
        
        # DeÄŸiÅŸiklikleri AlgÄ±lama ve Kaydetme
        original_status_series = df_raw.loc[df_filtered.index, 'Investigation_Status']
        edited_status_series = edited_df_view['Investigation_Status']
        
        # Sadece deÄŸiÅŸiklik varsa RERUN yap
        if not edited_status_series.equals(original_status_series):
            changed_indices = edited_status_series[edited_status_series != original_status_series].index
            
            for index in changed_indices:
                 new_status = edited_df_view.loc[index, 'Investigation_Status']
                 st.session_state.df_raw.loc[index, 'Investigation_Status'] = new_status
            
            # DeÄŸiÅŸiklik kaydedildi, filtrelerin gÃ¼ncellenmesi iÃ§in yeniden Ã§alÄ±ÅŸtÄ±r
            try:
                 st.rerun() 
            except RerunException: # RerunException'Ä±n doÄŸru ÅŸekilde import edildiÄŸinden emin olun
                 pass
            
        st.markdown("---")
        st.subheader("â¬‡ï¸ EtiketlenmiÅŸ Veriyi DÄ±ÅŸa Aktar")
        
        @st.cache_data
        def convert_df_to_csv(df_filtered_placeholder):
            df_to_export = st.session_state.df_raw.loc[df_filtered_placeholder.index].copy()
            export_cols_base = REQUIRED_COLUMNS + ['unique_id', 'Investigation_Status', 'tahmin', 'tahmin_skoru'] 
            available_cols = [col for col in df_to_export.columns if col in export_cols_base]
            
            df_to_export = df_to_export.filter(items=list(set(available_cols)))
            # time kÃ¼tÃ¼phanesinin bu fonksiyon iÃ§inde kullanÄ±ldÄ±ÄŸÄ±ndan emin olun.
            import time
            return df_to_export.to_csv(index=False).encode('utf-8')
        
        csv = convert_df_to_csv(df_filtered) 
        
        st.download_button(
            label="EtiketlenmiÅŸ Veriyi Ä°ndir (CSV)",
            data=csv,
            file_name=f'kepler_analysis_data_{time.strftime("%Y%m%d")}.csv',
            mime='text/csv',
            type="secondary",
            use_container_width=True
        )

# -----------------------------------------------------------
# 5. UYGULAMA ANA GÃ–VDESÄ° VE AKIÅ YÃ–NETÄ°MÄ°
# -----------------------------------------------------------

# CLASSIFIER deÄŸiÅŸkenini None olarak baÅŸlatmak daha gÃ¼venlidir.
CLASSIFIER = None

try:
    # ğŸ¯ NameError DÃ¼zeltmesi: SÄ±nÄ±f adÄ± ExoplanetClassifierWrapper olarak deÄŸiÅŸtirildi.
    CLASSIFIER = ExoplanetClassifierWrapper() 
except RuntimeError:
    # Model yÃ¼klenemezse uygulamayÄ± durdur.
    st.error("Uygulama baÅŸlatÄ±lamadÄ±: Model sistemi yÃ¼klenemedi. LÃ¼tfen 'train.py'yi Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zdan emin olun.")
    st.stop()
    
    
# Session State'leri baÅŸlat (Mevcut stiliniz korunarak, toplu baÅŸlatma daha okunabilir olsa da)
if 'df_raw' not in st.session_state: st.session_state.df_raw = None
if 'show_results' not in st.session_state: st.session_state.show_results = False
if 'validation_issues' not in st.session_state: st.session_state.validation_issues = None
if 'selected_candidate_index' not in st.session_state: st.session_state.selected_candidate_index = 0
if 'last_trained_date' not in st.session_state: st.session_state.last_trained_date = "Bilinmiyor" 
if 'period_range' not in st.session_state: st.session_state.period_range = (0.0, 1000.0)
if 'score_threshold' not in st.session_state: st.session_state.score_threshold = 0.0
if 'status_filter' not in st.session_state: st.session_state.status_filter = INVESTIGATION_STATUS_OPTIONS 

# --- MERKEZÄ° ODAKLI BAÅLIK VE DURUM ALANI ---
col_main_title, col_status_panel = st.columns([3, 1])

with col_main_title:
    if st.session_state.df_raw is not None:
         st.title("ğŸ”­ Kepler-AI: Ã–tegezegen KeÅŸif AsistanÄ±")
         st.markdown("### **<span style='color:var(--primary-color);'>GeliÅŸmiÅŸ Yapay Zeka ile Kendi Veri Setlerinizi Analiz Edin.</span>**", unsafe_allow_html=True)
    else:
         st.markdown("---")


with col_status_panel:
    # display_central_status_panel fonksiyonunun Ã§aÄŸrÄ±ldÄ±ÄŸÄ±ndan emin olun.
    display_central_status_panel()

# -----------------------------------------------------------
# 4. UYGULAMA ANA AKIÅI
# -----------------------------------------------------------

# 1. KRÄ°TÄ°K DÃœZELTME (NameError'Ä± Ã‡Ã¶zer): uploaded_file her zaman tanÄ±mlÄ±dÄ±r.
uploaded_file = None 

if CLASSIFIER is None:
    # ------------------------------------------------------------------
    # MODEL YÃœKLEME BAÅARISIZ OLURSA
    # ------------------------------------------------------------------
    st.error("Uygulama baÅŸlatÄ±lamadÄ±: SÄ±nÄ±flandÄ±rma modeli yÃ¼klenemedi...")
    
# --- VERÄ° YÃœKLEME KONTROLÃœ (Mutlak Minimalist Ana Sayfa) ---
elif st.session_state.df_raw is None:
    # ------------------------------------------------------------------
    # DOSYA YÃœKLEME EKRANI (Estetik Ä°yileÅŸtirme YapÄ±ldÄ±)
    # ------------------------------------------------------------------
    
    # 1. Hero KapsayÄ±cÄ±yÄ± BaÅŸlat (CSS tarafÄ±ndan ortalanÄ±r)
    st.markdown("<div class='hero-container-v8'>", unsafe_allow_html=True)

    # 2. MarkayÄ± ve Alt BaÅŸlÄ±ÄŸÄ± GÃ¶ster (BaÅŸlÄ±klar CSS ile bÃ¼yÃ¼tÃ¼ldÃ¼ ve vurgulandÄ±)
    st.markdown("<p class='hero-main-title'>KEPLER-AI</p>", unsafe_allow_html=True)
    st.markdown("<p class='hero-subtitle'>VERÄ° GÃœVENLÄ°ÄÄ° VE AÃ‡IKLANABÄ°LÄ°R ANALÄ°Z PLATFORMU</p>", unsafe_allow_html=True)

    # 3. YÃ¼kleyiciyi Ortalamak Ä°Ã§in Dar SÃ¼tunlar ([1, 2, 1] oranÄ± ile odaklanmÄ±ÅŸ merkez)
    col_spacer_l, col_uploader, col_spacer_r = st.columns([1, 2, 1])

    with col_uploader:
        
        st.markdown("### 1. Yeni Veri Setinizi YÃ¼kleyin (CSV)", unsafe_allow_html=True)
        
        # 4. Dosya YÃ¼kleyici Widget'Ä±
        uploaded_file = st.file_uploader(
            "LÃ¼tfen Kepler/KOI formatÄ±ndaki CSV dosyanÄ±zÄ± buraya sÃ¼rÃ¼kle bÄ±rakÄ±n veya TÄ±klayÄ±n", 
            type=['csv'],
            key="main_uploader_v8"
        )

        # 5. BaÅŸarÄ±lÄ± YÃ¼kleme Geri Bildirimi (KullanÄ±cÄ± Deneyimi)
        if uploaded_file is not None and st.session_state.df_raw is None:
            # time import'unun app.py'nin en baÅŸÄ±nda yapÄ±ldÄ±ÄŸÄ±ndan emin olun.
            st.success("Dosya baÅŸarÄ±yla yÃ¼klendi! Veriler iÅŸlenmek Ã¼zere hazÄ±rlanÄ±yor...")
            time.sleep(0.5) 

        # 6. Format Gereksinimleri AÃ§Ä±klayÄ±cÄ±sÄ±
        with st.expander("â“ Zorunlu Veri FormatÄ± ve SÃ¼tun Gereksinimleri"):
             ml_required_cols = CLASSIFIER.feature_names if CLASSIFIER else REQUIRED_COLUMNS
             st.markdown(f"""
             - **ML Ä°Ã§in Zorunlu SÃ¼tunlar:** **`{', '.join(ml_required_cols)}`**
             - **Ã–nemli:** Kepler/KOI formatÄ±nda, baÅŸlÄ±k kÄ±smÄ± atlanmalÄ±dÄ±r (`skiprows=14`). Dosya bu formatta olmalÄ±dÄ±r.
             """)

    # 7. Hero KapsayÄ±cÄ±yÄ± Kapat
    st.markdown("</div>", unsafe_allow_html=True)
    st.markdown("---") 


# --- DOSYA Ä°ÅLEME VE YENÄ°DEN Ã‡ALIÅTIRMA (RERUN) ---
# 3. Ä°ÅLEME: uploaded_file yalnÄ±zca bu noktada Not None ise Ã§alÄ±ÅŸÄ±r.
if uploaded_file is not None:
    try:
        # 1. Ham veriyi yÃ¼kle ve Kepler formatÄ±na gÃ¶re 14 satÄ±rÄ± atla
        df_raw = pd.read_csv(uploaded_file, skiprows=14) 
        
        # 2-6. Veri Validasyonu, Temizleme, ID OluÅŸturma ve Tahmin HattÄ±
        missing_raw_cols = [col for col in REQUIRED_COLUMNS if col not in df_raw.columns]
        if missing_raw_cols:
            raise ValueError(f"YÃ¼klenen ham dosyada eksik zorunlu sÃ¼tunlar: {', '.join(missing_raw_cols)}") 

        df_cleaned, validation_issues = ExoplanetClassifierWrapper._validate_and_clean_data(df_raw, REQUIRED_COLUMNS)
        
        if df_cleaned.empty:
            raise ValueError("Temizleme iÅŸleminden sonra veri setinde geÃ§erli, temizlenmiÅŸ aday kalmadÄ±.")
            
        id_col_found = next((col for col in PREFERRED_ID_COLUMNS if col in df_raw.columns), None)
        if id_col_found:
             df_cleaned['unique_id'] = df_raw.loc[df_cleaned.index, id_col_found]
        else:
             df_cleaned['unique_id'] = df_cleaned.index + 1
             validation_issues.append("UyarÄ±: HiÃ§bir tercih edilen ID sÃ¼tunu bulunamadÄ±. SatÄ±r indeksi 'unique_id' olarak kullanÄ±ldÄ±.")

        if 'Investigation_Status' not in df_cleaned.columns:
             df_cleaned['Investigation_Status'] = INVESTIGATION_STATUS_OPTIONS[0]
             
        df_final = CLASSIFIER.predict_all(df_cleaned)
             
        # 7. Session State'e Kaydetme ve RERUN
        st.session_state.df_raw = df_final
        st.session_state.validation_issues = validation_issues
        st.session_state.show_results = False
        st.session_state.selected_candidate_index = 0
        
        min_p = df_final['koi_period'].min()
        max_p = df_final['koi_period'].max()
        st.session_state.period_range = (min_p, max_p) if min_p < max_p else (min_p, min_p + 1)
        
        st.rerun()  

    except RerunException:
        raise 
    
    except Exception as e:
        logger.exception("Dosya yÃ¼kleme veya veri iÅŸleme sÄ±rasÄ±nda beklenmeyen bir sorun oluÅŸtu.")  
        st.error(f"Genel Hata: Dosya yÃ¼kleme veya veri iÅŸleme sÄ±rasÄ±nda beklenmeyen bir sorun oluÅŸtu. Detay: {e}")
        st.session_state.df_raw = None
        st.stop()

# --- ANA Ä°Ã‡ERÄ°K (SEKMELER) ---
# 4. Sekmeli arayÃ¼z yalnÄ±zca veri yÃ¼klendikten sonra gÃ¶sterilir.
if st.session_state.df_raw is not None:
    
    st.markdown("---")
    
    tab_custom, tab_system = st.tabs(["ğŸš€ KENDÄ° VERÄ°NÄ°ZÄ° ANALÄ°Z EDÄ°N", "ğŸ›°ï¸ SÄ°STEM VE KEÅÄ°F BÄ°LDÄ°RÄ°MLERÄ°"])
    
    with tab_custom:
         custom_analysis_page(CLASSIFIER, REQUIRED_COLUMNS)
    
    with tab_system:
         system_status_page()