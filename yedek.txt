import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import io
import shap
import matplotlib.pyplot as plt
import warnings
import time 
from typing import Tuple, Dict, Any, List

# --- UYGULAMA YAPILANDIRMASI ve SABÄ°TLER ---

# Matplotlib backend ayarÄ±
try:
    # SHAP iÃ§in gerekli backend ayarÄ±
    plt.switch_backend('Agg')
except ImportError:
    pass

# UyarÄ±larÄ± bastÄ±rma
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
pd.options.mode.chained_assignment = None

# Modelin Ã§alÄ±ÅŸmasÄ± iÃ§in gereken zorunlu sÃ¼tunlar listesi
REQUIRED_COLUMNS = ['koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 
                    'koi_fpflag_co', 'koi_period', 'koi_depth', 
                    'koi_prad', 'koi_steff']

# Streamlit Sayfa AyarlarÄ±
st.set_page_config(
    page_title="Kepler-AI | Ã–tegezegen SÄ±nÄ±flandÄ±rma",
    layout="wide", # Layout wide, ancak iÃ§erik sÃ¼tunlarla ortalanacak
    initial_sidebar_state="auto"
)


# -----------------------------------------------------------
# 1. ML VARLIKLARINI CACHING EDEN FONKSÄ°YON
# -----------------------------------------------------------

@st.cache_resource(show_spinner="ğŸ‘½ Yapay Zeka VarlÄ±klarÄ± YÃ¼kleniyor...")
def load_ml_assets_cached():
    """Modeli, Ã¶lÃ§ekleyiciyi ve SHAP Explainer'Ä± gÃ¼venle yÃ¼kler."""
    
    MODEL_PATH = 'models/kepler_ai_best_model.joblib'
    SCALER_PATH = 'models/kepler_ai_scaler.joblib'
    FEATURES_PATH = 'models/kepler_ai_feature_names.joblib'
    
    try:
        if not os.path.exists(MODEL_PATH) or not os.path.exists(SCALER_PATH):
             raise FileNotFoundError(f"Model dosyalarÄ± bulunamadÄ±: {MODEL_PATH} veya {SCALER_PATH}")

        model = joblib.load(MODEL_PATH)
        scaler = joblib.load(SCALER_PATH)
        feature_names_list = joblib.load(FEATURES_PATH)
        # SHAP TreeExplainer sadece aÄŸaÃ§ tabanlÄ± modellerde kullanÄ±lÄ±r
        explainer = shap.TreeExplainer(model) 
        
        return model, scaler, feature_names_list, explainer
    except FileNotFoundError as e:
        st.error(f"Hata: Gerekli model dosyalarÄ± bulunamadÄ±. LÃ¼tfen 'models/' klasÃ¶rÃ¼nÃ¼n doÄŸru kurulduÄŸundan emin olun.")
        return None, None, None, None
    except Exception as e:
        st.error(f"Model yÃ¼kleme sÄ±rasÄ±nda beklenmeyen bir hata oluÅŸtu: {e}")
        return None, None, None, None

# -----------------------------------------------------------
# 2. MODEL SÄ°STEMÄ° SINIFI (Tahmin ve Yorumlama Boru HattÄ±)
# -----------------------------------------------------------

class ExoplanetClassifier:
    """Makine Ã¶ÄŸrenimi boru hattÄ±nÄ± yÃ¶neten ana sÄ±nÄ±f."""
    
    def __init__(self):
        self.model, self.scaler, self.feature_names, self.explainer = load_ml_assets_cached()
        if self.model is None or self.scaler is None:
             raise RuntimeError("Model yÃ¼klenemedi. Devam edilemiyor.")

    @staticmethod
    def _validate_and_clean_data(df_raw: pd.DataFrame, required_columns: list) -> Tuple[pd.DataFrame, List[str]]:
        """GELÄ°ÅMÄ°Å VERÄ° KALÄ°TESÄ° KONTROLÃœ VE TEMÄ°ZLEME SÄ°STEMÄ°"""
        df = df_raw.copy()
        initial_count = len(df)
        issues = []
        
        # Temel temizlik ve mantÄ±k kontrolleri (eksik/yanlÄ±ÅŸ deÄŸerler)
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        df_cleaned = df.dropna(subset=required_columns)
        dropped_nan_count = initial_count - len(df_cleaned)
        if dropped_nan_count > 0:
            issues.append(f"{dropped_nan_count} satÄ±rda temel Ã¶zelliklerde eksik (NaN/Inf) deÄŸer olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±.")
        
        df = df_cleaned.copy()
        
        # Astrofiziksel mantÄ±k kontrolleri
        
        dropped_period_count = len(df[df['koi_period'] <= 0])
        df = df[df['koi_period'] > 0]
        if dropped_period_count > 0:
             issues.append(f"{dropped_period_count} satÄ±rda yÃ¶rÃ¼nge periyodu sÄ±fÄ±r veya negatif olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±.")
        
        dropped_score_count = len(df[(df['koi_score'] < 0) | (df['koi_score'] > 1)])
        df = df[(df['koi_score'] >= 0) & (df['koi_score'] <= 1)]
        if dropped_score_count > 0:
            issues.append(f"{dropped_score_count} satÄ±rda skor [0, 1] aralÄ±ÄŸÄ± dÄ±ÅŸÄ±nda olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±.")
            
        dropped_prad_count = len(df[df['koi_prad'] <= 0])
        df = df[df['koi_prad'] > 0]
        if dropped_prad_count > 0:
            issues.append(f"{dropped_prad_count} satÄ±rda gezegen yarÄ±Ã§apÄ± sÄ±fÄ±r veya negatif olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±.")
            
        dropped_depth_count = len(df[df['koi_depth'] <= 0])
        df = df[df['koi_depth'] > 0]
        if dropped_depth_count > 0:
            issues.append(f"{dropped_depth_count} satÄ±rda geÃ§iÅŸ derinliÄŸi sÄ±fÄ±r veya negatif olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±.")

        fp_cols = ['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co']
        for col in fp_cols:
            invalid_flag_count = len(df[(df[col] != 0) & (df[col] != 1)])
            if invalid_flag_count > 0:
                 issues.append(f"{invalid_flag_count} satÄ±rda '{col}' bayraÄŸÄ± 0 veya 1 dÄ±ÅŸÄ±nda olduÄŸu iÃ§in Ã§Ä±karÄ±ldÄ±.")
                 df = df[(df[col] == 0) | (df[col] == 1)]

        final_count = len(df)
        if final_count < initial_count:
            issues.insert(0, f"**Toplam {initial_count - final_count} satÄ±r KONTROL SÄ°STEMÄ° tarafÄ±ndan geÃ§ersiz veri nedeniyle atÄ±ldÄ±.**")
            
        return df, issues
    
    @staticmethod
    def _feature_engineering_and_alignment(df_raw_row: pd.DataFrame, feature_names: list) -> pd.DataFrame:
        """YÃ¼ksek Hassasiyetli Ã–znitelik MÃ¼hendisliÄŸi ve SÃ¼tun Hizalama."""
        df_new = df_raw_row.copy()
        EPSILON = 1e-12 

        df_new['R_PRAD_log'] = np.log10(df_new['koi_prad'].replace(0, EPSILON))
        df_new['R_PERIOD_log'] = np.log10(df_new['koi_period'].replace(0, EPSILON))
        df_new['R_DEPTH_log'] = np.log10(df_new['koi_depth'].replace(0, EPSILON))
        
        df_new['koi_density_proxy'] = df_new['koi_prad'] / (df_new['koi_period'].replace(0, EPSILON) ** (1/3))
        df_new['koi_depth_teff_int'] = df_new['koi_depth'] * df_new['koi_steff']
        
        df_aligned = pd.DataFrame(0.0, index=df_new.index, columns=feature_names, dtype=np.float64)
        
        for col in df_new.columns:
            if col in df_aligned.columns:
                df_aligned.loc[:, col] = df_new.loc[:, col].astype(np.float64)
                
        return df_aligned
    
    def _get_confidence_robust(self, X_scaled: np.ndarray, num_runs: int = 10) -> Tuple[str, float]:
        """Monte Carlo GÃ¼ven Tahmini (10 tekrar - KararlÄ± sonuÃ§ iÃ§in gÃ¼rÃ¼ltÃ¼ eklenir)"""
        
        JITTER_SCALE = 0.001 
        
        all_probabilities = []
        
        for _ in range(num_runs):
            # Monte Carlo simÃ¼lasyonu iÃ§in Ã¶lÃ§eklenmiÅŸ veriye hafif gÃ¼rÃ¼ltÃ¼ ekleme
            X_jittered = X_scaled + np.random.normal(0, JITTER_SCALE, X_scaled.shape)
            proba = self.model.predict_proba(X_jittered)[0]
            all_probabilities.append(proba)
            
        avg_probabilities = np.mean(all_probabilities, axis=0)
        
        prediction_label = "GEZEGEN/ADAY" if avg_probabilities[1] > 0.5 else "YANLIÅ POZÄ°TÄ°F (FALSE POSITIVE)"
        confidence = max(avg_probabilities)
        
        return prediction_label, confidence
    
    def predict(self, df_raw: pd.DataFrame, row_index: int) -> Tuple[str, float, io.BytesIO, Dict[str, Any]]:
        """TÃ¼m tahmin boru hattÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r."""
        
        df_raw_row = df_raw.iloc[[row_index]]
            
        # 1. Hizalama ve Ã–lÃ§ekleme
        X_aligned = self._feature_engineering_and_alignment(df_raw_row, self.feature_names)
        X_scaled = self.scaler.transform(X_aligned.values)
        
        # 2. Tahmin
        prediction_label, confidence = self._get_confidence_robust(X_scaled, num_runs=10)
        
        # 3. SHAP YorumlamasÄ±
        shap_values = self.explainer.shap_values(X_scaled) 
        
        # SHAP deÄŸerlerini uygun sÄ±nÄ±fa gÃ¶re seÃ§me
        if isinstance(shap_values, list):
            target_class_index = 1 if len(shap_values) > 1 else 0
            values_to_plot = shap_values[target_class_index][0] 
            base_value_to_plot = self.explainer.expected_value[target_class_index]
        elif isinstance(shap_values, np.ndarray):
            if shap_values.ndim == 3:
                values_to_plot = shap_values[0, :, 1]
                base_value_to_plot = self.explainer.expected_value[1]
            elif shap_values.ndim == 2:
                values_to_plot = shap_values[0, :]
                base_value_to_plot = self.explainer.expected_value
            else:
                raise TypeError("SHAP Ã§Ä±ktÄ± boyutu tanÄ±nmadÄ±.")

        if isinstance(base_value_to_plot, np.ndarray):
             base_value_to_plot = base_value_to_plot.flatten()[0]
        
        # --- KOYU TEMA Ä°Ã‡Ä°N SHAP GÃ–RSELÄ°NÄ° UYARLAMA ---
        # GÃ¶rseli IO Buffer'a kaydetme
        fig, ax = plt.subplots(figsize=(10, 6), facecolor='#0E1117') 
        
        shap.waterfall_plot(shap.Explanation(
            values=values_to_plot, 
            base_values=base_value_to_plot, 
            data=X_scaled[0], 
            feature_names=self.feature_names), max_display=15, show=False)
        
        # Koyu tema uyumu iÃ§in yazÄ± renklerini beyaza ayarlama
        ax.tick_params(axis='x', colors='white')
        ax.tick_params(axis='y', colors='white')
        plt.title(f"KOI AdayÄ± {row_index+1} iÃ§in Model Karar AÃ§Ä±klamasÄ±", color='white')
        
        buf = io.BytesIO()
        plt.savefig(buf, format="png", bbox_inches="tight", facecolor='#0E1117')
        plt.close(fig)
        
        return prediction_label, confidence, buf, df_raw_row.iloc[0].to_dict()

# -----------------------------------------------------------
# 3. STREAMLIT ANA UYGULAMA MANTIÄI
# -----------------------------------------------------------

try:
    # Uygulama baÅŸlatÄ±ldÄ±ÄŸÄ±nda modelin yÃ¼klenmesini denetle
    CLASSIFIER = ExoplanetClassifier()
except RuntimeError as e:
    # Model yÃ¼klenemezse uygulamayÄ± durdur
    st.error(f"Uygulama baÅŸlatÄ±lamadÄ±: {e}")
    st.stop()


# --- MERKEZÄ° ODAKLI BAÅLIK ALANI (EKRANIN YAKLAÅIK %43'Ãœ) ---
# [2 (BoÅŸluk), 3 (Ä°Ã§erik), 2 (BoÅŸluk)]
col_left_title, col_center_title, col_right_title = st.columns([2, 3, 2])

with col_center_title:
    st.title("ğŸ”­ Kepler-AI: Ã–tegezegen SÄ±nÄ±flandÄ±rma ve Yorumlama")
    st.markdown("Veri kalitesi kontrolÃ¼nden geÃ§irilen **maksimum hassasiyetli** verilerle yÃ¼ksek gÃ¼venilirlikli tahminler Ã¼retilir.")

# 5 saniyelik yÃ¼kleme animasyonu fonksiyonu
def run_simulation_animation(candidate_name, total_duration=5.0):
    """5 saniyelik, 5 aÅŸamalÄ± gÃ¶rsel bekleme barÄ±nÄ± Streamlit API'ye uygun Ã§alÄ±ÅŸtÄ±rÄ±r."""
    
    # Animasyonu merkezileÅŸtir
    col_left_anim, col_center_anim, col_right_anim = st.columns([2, 3, 2])
    
    with col_center_anim:
        status_placeholder = st.empty()
        progress_bar = st.progress(0)
        
        status_placeholder.subheader(f"ğŸ’« Aday {candidate_name} iÃ§in YÃ¼ksek GÃ¼venilirlikli Analiz BaÅŸlatÄ±ldÄ±...")

        # AÅŸamalar ve ilerleme yÃ¼zdeleri
        stages = [
            (0.1, "1/5: Veri Ã–zellikleri YÃ¼ksek Hassasiyetle HizalanÄ±yor (Float64)"),
            (0.3, "2/5: Monte Carlo SimÃ¼lasyonu BaÅŸlatÄ±lÄ±yor (Rastgele GÃ¼rÃ¼ltÃ¼ Ekleme)"),
            (0.6, "3/5: Yapay Zeka Modeli 10 FarklÄ± SimÃ¼lasyonu EÅŸzamanlÄ± Ä°ÅŸliyor..."),
            (0.9, "4/5: OlasÄ±lÄ±k SkorlarÄ± Ortalama GÃ¼venilirlik Ä°Ã§in BirleÅŸtiriliyor..."),
            (1.0, "5/5: SHAP DeÄŸerleri HesaplandÄ± ve Karar AÃ§Ä±klamasÄ± OluÅŸturuluyor.")
        ]
        
        current_progress = 0.0
        start_time = time.time()
        
        for target_progress, message in stages:
            progress_increment = (target_progress - current_progress)
            time_to_wait = total_duration * progress_increment 
            num_steps = 20
            step_delay = time_to_wait / num_steps if num_steps > 0 else 0
            step_increment = progress_increment / num_steps if num_steps > 0 else progress_increment
            
            for _ in range(num_steps):
                current_progress += step_increment
                progress_bar.progress(min(current_progress, target_progress))
                status_placeholder.markdown(f"**{message}**")
                time.sleep(step_delay)
                
            current_progress = target_progress
            progress_bar.progress(current_progress)

        remaining_time = total_duration - (time.time() - start_time)
        if remaining_time > 0:
            time.sleep(remaining_time)
        
        progress_bar.empty()
        status_placeholder.empty()
        st.success(f"âœ… Analiz TamamlandÄ±! Aday {candidate_name} iÃ§in sonuÃ§lar hazÄ±r.")
        time.sleep(0.5)

# --- MERKEZÄ° YÃœKLEME ALANI ---
prediction_container = st.container()
upload_placeholder = st.empty()
uploaded_file = None 

# 1. NO FILE UPLOADED: Show the central, focused upload area
with upload_placeholder.container():
    st.markdown("<br><br><br>", unsafe_allow_html=True)
    
    # YÃ¼kleyiciyi merkezileÅŸtir
    col_left, col_center, col_right = st.columns([2, 3, 2]) 
    
    with col_center:
        st.header("1. Kepler Veri Setini YÃ¼kle ğŸŒ ")
        st.markdown("### **<span style='color:#FF9900;'>Yapay Zeka ile Ã–tegezegen AdaylarÄ±nÄ± Bir TÄ±kla Temizle ve Analiz Et.</span>**", unsafe_allow_html=True)
        st.markdown("---")
        
        # Merkezi Dosya YÃ¼kleyici
        uploaded_file = st.file_uploader(
            "LÃ¼tfen filtrelenmiÅŸ Kepler/KOI CSV dosyasÄ±nÄ± buraya sÃ¼rÃ¼kle bÄ±rak veya TÄ±kla (.csv)", 
            type=['csv'],
            key="main_uploader"
        )
        st.markdown("<br><br><br>", unsafe_allow_html=True)

# Dosya yÃ¼klenmiÅŸse (uploaded_file is not None)
if uploaded_file is not None:
    # Merkezi yÃ¼kleme ekranÄ±nÄ± temizle
    upload_placeholder.empty()

    try:
        # Veri okuma ve temizleme
        df_raw = pd.read_csv(uploaded_file, skiprows=14)
        missing_cols = [col for col in REQUIRED_COLUMNS if col not in df_raw.columns]
        
        if missing_cols:
            st.error(f"Hata: YÃ¼klenen CSV dosyasÄ±nda eksik zorunlu sÃ¼tunlar var: **{', '.join(missing_cols)}**")
            st.stop() 

        df_cleaned, validation_issues = ExoplanetClassifier._validate_and_clean_data(df_raw, REQUIRED_COLUMNS)
        
        if df_cleaned.empty:
            st.error("Hata: YÃ¼klenen dosyada tÃ¼m temizlik kontrollerini geÃ§en geÃ§erli aday kalmadÄ±.")
            if validation_issues:
                st.warning("Tespit edilen ve Ã§Ä±karÄ±lan veri sorunlarÄ±:")
                for issue in validation_issues:
                    st.write(f"- {issue}")
            st.stop()
            
        df_raw = df_cleaned
        
        # 2. Sidebar'Ä± Analiz Kontrolleri ile doldur
        st.sidebar.header("2. Aday SeÃ§imi ve Kontroller")
        st.sidebar.info("YÃ¼ksek gÃ¼venilirlikli tahminler iÃ§in Monte Carlo simÃ¼lasyonu kullanÄ±lacaktÄ±r.")
        
        st.sidebar.success(f"Veri YÃ¼klendi. Kalan **{len(df_raw)}** saÄŸlam aday analiz iÃ§in hazÄ±r.")
        
        candidate_index = st.sidebar.selectbox(
            label="Analiz Edilecek AdayÄ± SeÃ§in (SatÄ±r NumarasÄ±)",
            options=list(range(len(df_raw))),
            format_func=lambda i: f"Aday {i+1} (Orijinal SatÄ±r No: {df_raw.index[i] + 1})"
        )
        
        # GeliÅŸmiÅŸ veri temizlik raporu (Expander iÃ§inde)
        if validation_issues and len(validation_issues) > 1:
            st.sidebar.warning("Veri Kontrol Sisteminden Ã–zet:")
            st.sidebar.markdown(validation_issues[0]) 
            with st.sidebar.expander("DetaylÄ± Temizlik Raporunu GÃ¶r"):
                for issue in validation_issues[1:]:
                     st.write(f"- {issue}")

        
        if st.sidebar.button('ğŸš€ SeÃ§ili AdayÄ± Tahmin Et ve Yorumla', type="primary"):
            
            # YÃ¼kleme animasyonu Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r
            run_simulation_animation(candidate_index + 1)
            
            # Tahmin Ã§alÄ±ÅŸÄ±r
            prediction, confidence, shap_buffer, raw_data = CLASSIFIER.predict(df_raw, candidate_index)
            
            with prediction_container:
                
                # --- SONUÃ‡ ALANINI ORTALAMA ---
                col_left_res, col_center_res, col_right_res = st.columns([2, 3, 2])
                
                with col_center_res:
                    
                    # 3. SonuÃ§ BaÅŸlÄ±ÄŸÄ±
                    st.header(f"3. ğŸ›°ï¸ Aday {candidate_index+1} iÃ§in Analiz Sonucu")
                    
                    is_false_positive = "YANLIÅ" in prediction
                    emoji = "ğŸš¨" if is_false_positive else "âœ…"
                    
                    st.markdown("---")
                    
                    # --- MODERN METRÄ°K GRUPLAMA: TAHMÄ°N Ã–ZETÄ° ---
                    st.markdown("## ğŸ¯ Tahmin Ã–zeti")
                    
                    # 1. SatÄ±r: Ana SonuÃ§ ve GÃ¼ven
                    col_pred, col_conf = st.columns([1, 1]) 
                    
                    with col_pred:
                        st.metric(label="SÄ±nÄ±flandÄ±rma Sonucu", 
                                  value=f"{prediction}", 
                                  delta=emoji)
                    
                    with col_conf:
                        st.metric(label="Model GÃ¼veni (10x Monte Carlo)", 
                                  value=f"{confidence:.2%}",
                                  delta="YÃ¼ksek KararlÄ±lÄ±k")
                    
                    st.markdown("<br>", unsafe_allow_html=True) # Hafif dikey boÅŸluk

                    # 2. SatÄ±r: Astrofiziksel Veriler
                    col_prad, col_period, col_flag = st.columns(3)
                    
                    with col_prad:
                        # DÃœZELTME: SyntaxWarning'i gidermek iÃ§in 'raw string' kaldÄ±rÄ±ldÄ±.
                        st.metric("Gezegen YarÄ±Ã§apÄ± (Prad)", f"{raw_data.get('koi_prad', 0.0):.2f} $R_{{\oplus}}$")
                    with col_period:
                        st.metric("YÃ¶rÃ¼nge Periyodu", f"{raw_data.get('koi_period', 0.0):.2f} GÃ¼n")
                    with col_flag:
                        st.metric("Merkez KaymasÄ± BayraÄŸÄ±", f"{int(raw_data.get('koi_fpflag_co', 0))}")
                    
                    st.markdown("---")

                    # --- SHAP GÃ–RSELÄ° ---
                    st.header("ğŸ”¬ Modelin Karar Analizi (SHAP)")
                    st.info("AÅŸaÄŸÄ±daki gÃ¶rsel, modelin kararÄ±nÄ± verirken hangi Ã¶zelliklerin sonucu ne yÃ¶nde etkilediÄŸini gÃ¶steren gÃ¼venilir kanÄ±ttÄ±r.")
                    
                    # DÃœZELTME: DeprecationWarning'i gidermek iÃ§in use_container_width yerine width='stretch' kullanÄ±ldÄ±.
                    st.image(shap_buffer, caption=f'Aday {candidate_index+1} iÃ§in SHAP GÃ¶rseli', width='stretch') 


    except RuntimeError as e:
        # Ã‡alÄ±ÅŸma zamanÄ± model/Ã¶lÃ§ekleyici hatasÄ±
        st.error(f"Uygulama Ã‡alÄ±ÅŸtÄ±rma HatasÄ±: {e}. Model varlÄ±klarÄ±nÄ±n doÄŸru yÃ¼klendiÄŸinden emin olun.")
    except Exception as e:
        # Genel beklemedik hata
        st.exception(e) 
        st.error(f"Genel Hata: Uygulama sÄ±rasÄ±nda beklenmeyen bir sorun oluÅŸtu. Detay: {type(e).__name__}: {e}")